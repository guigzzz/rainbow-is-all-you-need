{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations for Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    !apt install python-opengl\n",
    "    !apt install ffmpeg\n",
    "    !apt install xvfb\n",
    "    !pip install PyVirtualDisplay==3.0\n",
    "    !pip install gymnasium==0.28.1\n",
    "    from pyvirtualdisplay import Display\n",
    "    \n",
    "    # Start virtual display\n",
    "    dis = Display(visible=0, size=(400, 400))\n",
    "    dis.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08. Rainbow\n",
    "\n",
    "[M. Hessel et al., \"Rainbow: Combining Improvements in Deep Reinforcement Learning.\" arXiv preprint arXiv:1710.02298, 2017.](https://arxiv.org/pdf/1710.02298.pdf)\n",
    "\n",
    "We will integrate all the following seven components into a single integrated agent, which is called Rainbow!\n",
    "\n",
    "1. DQN\n",
    "2. Double DQN\n",
    "3. Prioritized Experience Replay\n",
    "4. Dueling Network\n",
    "5. Noisy Network\n",
    "6. Categorical DQN\n",
    "7. N-step Learning\n",
    "\n",
    "This method shows an impressive performance on the Atari 2600 benchmark, both in terms of data efficiency and final performance. \n",
    "\n",
    "![rainbow](https://user-images.githubusercontent.com/14961526/60591412-61748100-9dd9-11e9-84fb-076c7a61fbab.png)\n",
    "\n",
    "However, the integration is not so simple because some of components are not independent each other, so we will look into a number of points that people especailly feel confused.\n",
    "\n",
    "1. Noisy Network <-> Dueling Network\n",
    "2. Dueling Network <-> Categorical DQN\n",
    "3. Categorical DQN <-> Double DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guillaume/rainbow-is-all-you-need/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "from collections import deque\n",
    "from typing import Deque, Dict, List, Tuple\n",
    "\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from IPython.display import clear_output\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "# download segment tree module\n",
    "if IN_COLAB:\n",
    "    !wget https://raw.githubusercontent.com/curt-park/rainbow-is-all-you-need/master/segment_tree.py\n",
    "\n",
    "from segment_tree import MinSegmentTree, SumSegmentTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replay buffer\n",
    "\n",
    "Same as the basic N-step buffer. \n",
    "\n",
    "(Please see *01.dqn.ipynb*, *07.n_step_learning.ipynb* for detailed description about the basic (n-step) replay buffer.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"A simple numpy replay buffer.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        obs_dim: int, \n",
    "        size: int, \n",
    "        batch_size: int = 32, \n",
    "        n_step: int = 1, \n",
    "        gamma: float = 0.99\n",
    "    ):\n",
    "        self.obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "        self.next_obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "        self.acts_buf = np.zeros([size], dtype=np.float32)\n",
    "        self.rews_buf = np.zeros([size], dtype=np.float32)\n",
    "        self.done_buf = np.zeros(size, dtype=np.float32)\n",
    "        self.max_size, self.batch_size = size, batch_size\n",
    "        self.ptr, self.size, = 0, 0\n",
    "        \n",
    "        # for N-step Learning\n",
    "        self.n_step_buffer = deque(maxlen=n_step)\n",
    "        self.n_step = n_step\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def store(\n",
    "        self, \n",
    "        obs: np.ndarray, \n",
    "        act: np.ndarray, \n",
    "        rew: float, \n",
    "        next_obs: np.ndarray, \n",
    "        done: bool,\n",
    "    ) -> Tuple[np.ndarray, np.ndarray, float, np.ndarray, bool]:\n",
    "        transition = (obs, act, rew, next_obs, done)\n",
    "        self.n_step_buffer.append(transition)\n",
    "\n",
    "        # single step transition is not ready\n",
    "        if len(self.n_step_buffer) < self.n_step:\n",
    "            return ()\n",
    "        \n",
    "        # make a n-step transition\n",
    "        rew, next_obs, done = self._get_n_step_info(\n",
    "            self.n_step_buffer, self.gamma\n",
    "        )\n",
    "        obs, act = self.n_step_buffer[0][:2]\n",
    "        \n",
    "        self.obs_buf[self.ptr] = obs\n",
    "        self.next_obs_buf[self.ptr] = next_obs\n",
    "        self.acts_buf[self.ptr] = act\n",
    "        self.rews_buf[self.ptr] = rew\n",
    "        self.done_buf[self.ptr] = done\n",
    "        self.ptr = (self.ptr + 1) % self.max_size\n",
    "        self.size = min(self.size + 1, self.max_size)\n",
    "        \n",
    "        return self.n_step_buffer[0]\n",
    "\n",
    "    def sample_batch(self) -> Dict[str, np.ndarray]:\n",
    "        idxs = np.random.choice(self.size, size=self.batch_size, replace=False)\n",
    "\n",
    "        return dict(\n",
    "            obs=self.obs_buf[idxs],\n",
    "            next_obs=self.next_obs_buf[idxs],\n",
    "            acts=self.acts_buf[idxs],\n",
    "            rews=self.rews_buf[idxs],\n",
    "            done=self.done_buf[idxs],\n",
    "            # for N-step Learning\n",
    "            indices=idxs,\n",
    "        )\n",
    "    \n",
    "    def sample_batch_from_idxs(\n",
    "        self, idxs: np.ndarray\n",
    "    ) -> Dict[str, np.ndarray]:\n",
    "        # for N-step Learning\n",
    "        return dict(\n",
    "            obs=self.obs_buf[idxs],\n",
    "            next_obs=self.next_obs_buf[idxs],\n",
    "            acts=self.acts_buf[idxs],\n",
    "            rews=self.rews_buf[idxs],\n",
    "            done=self.done_buf[idxs],\n",
    "        )\n",
    "    \n",
    "    def _get_n_step_info(\n",
    "        self, n_step_buffer: Deque, gamma: float\n",
    "    ) -> Tuple[np.int64, np.ndarray, bool]:\n",
    "        \"\"\"Return n step rew, next_obs, and done.\"\"\"\n",
    "        # info of the last transition\n",
    "        rew, next_obs, done = n_step_buffer[-1][-3:]\n",
    "\n",
    "        for transition in reversed(list(n_step_buffer)[:-1]):\n",
    "            r, n_o, d = transition[-3:]\n",
    "\n",
    "            rew = r + gamma * rew * (1 - d)\n",
    "            next_obs, done = (n_o, d) if d else (next_obs, done)\n",
    "\n",
    "        return rew, next_obs, done\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prioritized replay Buffer\n",
    "\n",
    "`store` method returns boolean in order to inform if a N-step transition has been generated.\n",
    "\n",
    "(Please see *02.per.ipynb* for detailed description about PER.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrioritizedReplayBuffer(ReplayBuffer):\n",
    "    \"\"\"Prioritized Replay buffer.\n",
    "    \n",
    "    Attributes:\n",
    "        max_priority (float): max priority\n",
    "        tree_ptr (int): next index of tree\n",
    "        alpha (float): alpha parameter for prioritized replay buffer\n",
    "        sum_tree (SumSegmentTree): sum tree for prior\n",
    "        min_tree (MinSegmentTree): min tree for min prior to get max weight\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        obs_dim: int, \n",
    "        size: int, \n",
    "        batch_size: int = 32, \n",
    "        alpha: float = 0.6,\n",
    "        n_step: int = 1, \n",
    "        gamma: float = 0.99,\n",
    "    ):\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        assert alpha >= 0\n",
    "        \n",
    "        super(PrioritizedReplayBuffer, self).__init__(\n",
    "            obs_dim, size, batch_size, n_step, gamma\n",
    "        )\n",
    "        self.max_priority, self.tree_ptr = 1.0, 0\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        # capacity must be positive and a power of 2.\n",
    "        tree_capacity = 1\n",
    "        while tree_capacity < self.max_size:\n",
    "            tree_capacity *= 2\n",
    "\n",
    "        self.sum_tree = SumSegmentTree(tree_capacity)\n",
    "        self.min_tree = MinSegmentTree(tree_capacity)\n",
    "        \n",
    "    def store(\n",
    "        self, \n",
    "        obs: np.ndarray, \n",
    "        act: int, \n",
    "        rew: float, \n",
    "        next_obs: np.ndarray, \n",
    "        done: bool,\n",
    "    ) -> Tuple[np.ndarray, np.ndarray, float, np.ndarray, bool]:\n",
    "        \"\"\"Store experience and priority.\"\"\"\n",
    "        transition = super().store(obs, act, rew, next_obs, done)\n",
    "        \n",
    "        if transition:\n",
    "            self.sum_tree[self.tree_ptr] = self.max_priority ** self.alpha\n",
    "            self.min_tree[self.tree_ptr] = self.max_priority ** self.alpha\n",
    "            self.tree_ptr = (self.tree_ptr + 1) % self.max_size\n",
    "        \n",
    "        return transition\n",
    "\n",
    "    def sample_batch(self, beta: float = 0.4) -> Dict[str, np.ndarray]:\n",
    "        \"\"\"Sample a batch of experiences.\"\"\"\n",
    "        assert len(self) >= self.batch_size\n",
    "        assert beta > 0\n",
    "        \n",
    "        indices = self._sample_proportional()\n",
    "        \n",
    "        obs = self.obs_buf[indices]\n",
    "        next_obs = self.next_obs_buf[indices]\n",
    "        acts = self.acts_buf[indices]\n",
    "        rews = self.rews_buf[indices]\n",
    "        done = self.done_buf[indices]\n",
    "        weights = np.array([self._calculate_weight(i, beta) for i in indices])\n",
    "        \n",
    "        return dict(\n",
    "            obs=obs,\n",
    "            next_obs=next_obs,\n",
    "            acts=acts,\n",
    "            rews=rews,\n",
    "            done=done,\n",
    "            weights=weights,\n",
    "            indices=indices,\n",
    "        )\n",
    "        \n",
    "    def update_priorities(self, indices: List[int], priorities: np.ndarray):\n",
    "        \"\"\"Update priorities of sampled transitions.\"\"\"\n",
    "        assert len(indices) == len(priorities)\n",
    "\n",
    "        for idx, priority in zip(indices, priorities):\n",
    "            assert priority > 0\n",
    "            assert 0 <= idx < len(self)\n",
    "\n",
    "            self.sum_tree[idx] = priority ** self.alpha\n",
    "            self.min_tree[idx] = priority ** self.alpha\n",
    "\n",
    "            self.max_priority = max(self.max_priority, priority)\n",
    "            \n",
    "    def _sample_proportional(self) -> List[int]:\n",
    "        \"\"\"Sample indices based on proportions.\"\"\"\n",
    "        indices = []\n",
    "        p_total = self.sum_tree.sum(0, len(self) - 1)\n",
    "        segment = p_total / self.batch_size\n",
    "        \n",
    "        for i in range(self.batch_size):\n",
    "            a = segment * i\n",
    "            b = segment * (i + 1)\n",
    "            upperbound = random.uniform(a, b)\n",
    "            idx = self.sum_tree.retrieve(upperbound)\n",
    "            indices.append(idx)\n",
    "            \n",
    "        return indices\n",
    "    \n",
    "    def _calculate_weight(self, idx: int, beta: float):\n",
    "        \"\"\"Calculate the weight of the experience at idx.\"\"\"\n",
    "        # get max weight\n",
    "        p_min = self.min_tree.min() / self.sum_tree.sum()\n",
    "        max_weight = (p_min * len(self)) ** (-beta)\n",
    "        \n",
    "        # calculate weights\n",
    "        p_sample = self.sum_tree[idx] / self.sum_tree.sum()\n",
    "        weight = (p_sample * len(self)) ** (-beta)\n",
    "        weight = weight / max_weight\n",
    "        \n",
    "        return weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noisy Layer\n",
    "\n",
    "Please see *05.noisy_net.ipynb* for detailed description.\n",
    "\n",
    "**References:**\n",
    "\n",
    "- https://github.com/higgsfield/RL-Adventure/blob/master/5.noisy%20dqn.ipynb\n",
    "- https://github.com/Kaixhin/Rainbow/blob/master/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoisyLinear(nn.Module):\n",
    "    \"\"\"Noisy linear module for NoisyNet.\n",
    "    \n",
    "    \n",
    "        \n",
    "    Attributes:\n",
    "        in_features (int): input size of linear module\n",
    "        out_features (int): output size of linear module\n",
    "        std_init (float): initial std value\n",
    "        weight_mu (nn.Parameter): mean value weight parameter\n",
    "        weight_sigma (nn.Parameter): std value weight parameter\n",
    "        bias_mu (nn.Parameter): mean value bias parameter\n",
    "        bias_sigma (nn.Parameter): std value bias parameter\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_features: int, \n",
    "        out_features: int, \n",
    "        std_init: float = 0.5,\n",
    "    ):\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        super(NoisyLinear, self).__init__()\n",
    "        \n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.std_init = std_init\n",
    "\n",
    "        self.weight_mu = nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "        self.weight_sigma = nn.Parameter(\n",
    "            torch.Tensor(out_features, in_features)\n",
    "        )\n",
    "        self.register_buffer(\n",
    "            \"weight_epsilon\", torch.Tensor(out_features, in_features)\n",
    "        )\n",
    "\n",
    "        self.bias_mu = nn.Parameter(torch.Tensor(out_features))\n",
    "        self.bias_sigma = nn.Parameter(torch.Tensor(out_features))\n",
    "        self.register_buffer(\"bias_epsilon\", torch.Tensor(out_features))\n",
    "\n",
    "        self.reset_parameters()\n",
    "        self.reset_noise()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"Reset trainable network parameters (factorized gaussian noise).\"\"\"\n",
    "        mu_range = 1 / math.sqrt(self.in_features)\n",
    "        self.weight_mu.data.uniform_(-mu_range, mu_range)\n",
    "        self.weight_sigma.data.fill_(\n",
    "            self.std_init / math.sqrt(self.in_features)\n",
    "        )\n",
    "        self.bias_mu.data.uniform_(-mu_range, mu_range)\n",
    "        self.bias_sigma.data.fill_(\n",
    "            self.std_init / math.sqrt(self.out_features)\n",
    "        )\n",
    "\n",
    "    def reset_noise(self):\n",
    "        \"\"\"Make new noise.\"\"\"\n",
    "        epsilon_in = self.scale_noise(self.in_features)\n",
    "        epsilon_out = self.scale_noise(self.out_features)\n",
    "\n",
    "        # outer product\n",
    "        self.weight_epsilon.copy_(epsilon_out.ger(epsilon_in))\n",
    "        self.bias_epsilon.copy_(epsilon_out)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward method implementation.\n",
    "        \n",
    "        We don't use separate statements on train / eval mode.\n",
    "        It doesn't show remarkable difference of performance.\n",
    "        \"\"\"\n",
    "        return F.linear(\n",
    "            x,\n",
    "            self.weight_mu + self.weight_sigma * self.weight_epsilon,\n",
    "            self.bias_mu + self.bias_sigma * self.bias_epsilon,\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def scale_noise(size: int) -> torch.Tensor:\n",
    "        \"\"\"Set scale to make noise (factorized gaussian noise).\"\"\"\n",
    "        x = torch.randn(size)\n",
    "\n",
    "        return x.sign().mul(x.abs().sqrt())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NoisyNet + DuelingNet + Categorical DQN\n",
    "\n",
    "#### NoisyNet + DuelingNet\n",
    "\n",
    "NoisyLinear is employed for the last two layers of advantage and value layers. The noise should be reset at evey update step.\n",
    "\n",
    "#### DuelingNet + Categorical DQN\n",
    "\n",
    "The dueling network architecture is adapted for use with return distributions. The network has a shared representation, which is then fed into a value stream with atom_size outputs, and into an advantage stream with atom_size × out_dim outputs. For each atom, the value and advantage streams are aggregated, as in dueling DQN, and then passed through a softmax layer to obtain the normalized parametric distributions used to estimate the returns’ distributions.\n",
    "\n",
    "```\n",
    "        advantage = self.advantage_layer(adv_hid).view(-1, self.out_dim, self.atom_size)\n",
    "        value = self.value_layer(val_hid).view(-1, 1, self.atom_size)\n",
    "        q_atoms = value + advantage - advantage.mean(dim=1, keepdim=True)\n",
    "        \n",
    "        dist = F.softmax(q_atoms, dim=-1)\n",
    "```\n",
    "\n",
    "(Please see *04.dueling.ipynb*, *05.noisy_net.ipynb*, *06.categorical_dqn.ipynb* for detailed description of each component's network architecture.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_dim: int, \n",
    "        out_dim: int, \n",
    "        atom_size: int, \n",
    "        support: torch.Tensor\n",
    "    ):\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        super(Network, self).__init__()\n",
    "        \n",
    "        self.support = support\n",
    "        self.out_dim = out_dim\n",
    "        self.atom_size = atom_size\n",
    "\n",
    "        # set common feature layer\n",
    "        self.feature_layer = nn.Sequential(\n",
    "            nn.Linear(in_dim, 128), \n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # set advantage layer\n",
    "        self.advantage_hidden_layer = NoisyLinear(128, 128)\n",
    "        self.advantage_layer = NoisyLinear(128, out_dim * atom_size)\n",
    "\n",
    "        # set value layer\n",
    "        self.value_hidden_layer = NoisyLinear(128, 128)\n",
    "        self.value_layer = NoisyLinear(128, atom_size)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward method implementation.\"\"\"\n",
    "        dist = self.dist(x)\n",
    "        q = torch.sum(dist * self.support, dim=2)\n",
    "        \n",
    "        return q\n",
    "    \n",
    "    def dist(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Get distribution for atoms.\"\"\"\n",
    "        feature = self.feature_layer(x)\n",
    "        adv_hid = F.relu(self.advantage_hidden_layer(feature))\n",
    "        val_hid = F.relu(self.value_hidden_layer(feature))\n",
    "        \n",
    "        advantage = self.advantage_layer(adv_hid).view(\n",
    "            -1, self.out_dim, self.atom_size\n",
    "        )\n",
    "        value = self.value_layer(val_hid).view(-1, 1, self.atom_size)\n",
    "        q_atoms = value + advantage - advantage.mean(dim=1, keepdim=True)\n",
    "        \n",
    "        dist = F.softmax(q_atoms, dim=-1)\n",
    "        dist = dist.clamp(min=1e-3)  # for avoiding nans\n",
    "        \n",
    "        return dist\n",
    "    \n",
    "    def reset_noise(self):\n",
    "        \"\"\"Reset all noisy layers.\"\"\"\n",
    "        self.advantage_hidden_layer.reset_noise()\n",
    "        self.advantage_layer.reset_noise()\n",
    "        self.value_hidden_layer.reset_noise()\n",
    "        self.value_layer.reset_noise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rainbow Agent\n",
    "\n",
    "Here is a summary of DQNAgent class.\n",
    "\n",
    "| Method           | Note                                                 |\n",
    "| ---              | ---                                                  |\n",
    "|select_action     | select an action from the input state.               |\n",
    "|step              | take an action and return the response of the env.   |\n",
    "|compute_dqn_loss  | return dqn loss.                                     |\n",
    "|update_model      | update the model by gradient descent.                |\n",
    "|target_hard_update| hard update from the local model to the target model.|\n",
    "|train             | train the agent during num_frames.                   |\n",
    "|test              | test the agent (1 episode).                          |\n",
    "|plot              | plot the training progresses.                        |\n",
    "\n",
    "#### Categorical DQN + Double DQN\n",
    "\n",
    "The idea of Double Q-learning is to reduce overestimations by decomposing the max operation in the target into action selection and action evaluation. Here, we use `self.dqn` instead of `self.dqn_target` to obtain the target actions.\n",
    "\n",
    "```\n",
    "        # Categorical DQN + Double DQN\n",
    "        # target_dqn is used when we don't employ double DQN\n",
    "        next_action = self.dqn(next_state).argmax(1)\n",
    "        next_dist = self.dqn_target.dist(next_state)\n",
    "        next_dist = next_dist[range(self.batch_size), next_action]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    \"\"\"DQN Agent interacting with environment.\n",
    "    \n",
    "    Attribute:\n",
    "        env (gym.Env): openAI Gym environment\n",
    "        memory (PrioritizedReplayBuffer): replay memory to store transitions\n",
    "        batch_size (int): batch size for sampling\n",
    "        target_update (int): period for target model's hard update\n",
    "        gamma (float): discount factor\n",
    "        dqn (Network): model to train and select actions\n",
    "        dqn_target (Network): target model to update\n",
    "        optimizer (torch.optim): optimizer for training dqn\n",
    "        transition (list): transition information including \n",
    "                           state, action, reward, next_state, done\n",
    "        v_min (float): min value of support\n",
    "        v_max (float): max value of support\n",
    "        atom_size (int): the unit number of support\n",
    "        support (torch.Tensor): support for categorical dqn\n",
    "        use_n_step (bool): whether to use n_step memory\n",
    "        n_step (int): step number to calculate n-step td error\n",
    "        memory_n (ReplayBuffer): n-step replay buffer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        env: gym.Env,\n",
    "        memory_size: int,\n",
    "        batch_size: int,\n",
    "        target_update: int,\n",
    "        seed: int,\n",
    "        gamma: float = 0.99,\n",
    "        # PER parameters\n",
    "        alpha: float = 0.2,\n",
    "        beta: float = 0.6,\n",
    "        prior_eps: float = 1e-6,\n",
    "        # Categorical DQN parameters\n",
    "        v_min: float = 0.0,\n",
    "        v_max: float = 200.0,\n",
    "        atom_size: int = 51,\n",
    "        # N-step Learning\n",
    "        n_step: int = 3,\n",
    "    ):\n",
    "        \"\"\"Initialization.\n",
    "        \n",
    "        Args:\n",
    "            env (gym.Env): openAI Gym environment\n",
    "            memory_size (int): length of memory\n",
    "            batch_size (int): batch size for sampling\n",
    "            target_update (int): period for target model's hard update\n",
    "            lr (float): learning rate\n",
    "            gamma (float): discount factor\n",
    "            alpha (float): determines how much prioritization is used\n",
    "            beta (float): determines how much importance sampling is used\n",
    "            prior_eps (float): guarantees every transition can be sampled\n",
    "            v_min (float): min value of support\n",
    "            v_max (float): max value of support\n",
    "            atom_size (int): the unit number of support\n",
    "            n_step (int): step number to calculate n-step td error\n",
    "        \"\"\"\n",
    "        obs_dim = 26 #env.observation_space.shape[0]\n",
    "        action_dim = env.action_space.n\n",
    "\n",
    "        print(obs_dim, action_dim)\n",
    "        \n",
    "        self.env = env\n",
    "        self.batch_size = batch_size\n",
    "        self.target_update = target_update\n",
    "        self.seed = seed\n",
    "        self.gamma = gamma\n",
    "        # NoisyNet: All attributes related to epsilon are removed\n",
    "        \n",
    "        # device: cpu / gpu\n",
    "        self.device = torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "        print(self.device)\n",
    "        \n",
    "        # PER\n",
    "        # memory for 1-step Learning\n",
    "        self.beta = beta\n",
    "        self.prior_eps = prior_eps\n",
    "        self.memory = PrioritizedReplayBuffer(\n",
    "            obs_dim, memory_size, batch_size, alpha=alpha\n",
    "        )\n",
    "        \n",
    "        # memory for N-step Learning\n",
    "        self.use_n_step = True if n_step > 1 else False\n",
    "        if self.use_n_step:\n",
    "            self.n_step = n_step\n",
    "            self.memory_n = ReplayBuffer(\n",
    "                obs_dim, memory_size, batch_size, n_step=n_step, gamma=gamma\n",
    "            )\n",
    "            \n",
    "        # Categorical DQN parameters\n",
    "        self.v_min = v_min\n",
    "        self.v_max = v_max\n",
    "        self.atom_size = atom_size\n",
    "        self.support = torch.linspace(\n",
    "            self.v_min, self.v_max, self.atom_size\n",
    "        ).to(self.device)\n",
    "\n",
    "        # networks: dqn, dqn_target\n",
    "        self.dqn = Network(\n",
    "            obs_dim, action_dim, self.atom_size, self.support\n",
    "        ).to(self.device)\n",
    "        self.dqn_target = Network(\n",
    "            obs_dim, action_dim, self.atom_size, self.support\n",
    "        ).to(self.device)\n",
    "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
    "        self.dqn_target.eval()\n",
    "        \n",
    "        # optimizer\n",
    "        self.optimizer = optim.Adam(self.dqn.parameters())\n",
    "\n",
    "        # transition to store in memory\n",
    "        self.transition = list()\n",
    "        \n",
    "        # mode: train / test\n",
    "        self.is_test = False\n",
    "\n",
    "    def select_action(self, state: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Select an action from the input state.\"\"\"\n",
    "        # NoisyNet: no epsilon greedy action selection\n",
    "\n",
    "        selected_action = self.dqn(\n",
    "            torch.FloatTensor(state).to(self.device)\n",
    "        )\n",
    "\n",
    "        selected_action = selected_action.detach().cpu().numpy()\n",
    "\n",
    "        print(selected_action)\n",
    "\n",
    "        selected_action = selected_action.argmax()\n",
    "        \n",
    "        if not self.is_test:\n",
    "            self.transition = [state, selected_action]\n",
    "\n",
    "        return selected_action\n",
    "\n",
    "    def step(self, action: np.ndarray) -> Tuple[np.ndarray, np.float64, bool]:\n",
    "        \"\"\"Take an action and return the response of the env.\"\"\"\n",
    "        next_state, reward, terminated, truncated, _ = self.env.step(action)\n",
    "        done = terminated or truncated\n",
    "        \n",
    "        if not self.is_test:\n",
    "            self.transition += [reward, next_state, done]\n",
    "            \n",
    "            # N-step transition\n",
    "            if self.use_n_step:\n",
    "                one_step_transition = self.memory_n.store(*self.transition)\n",
    "            # 1-step transition\n",
    "            else:\n",
    "                one_step_transition = self.transition\n",
    "\n",
    "            # add a single step transition\n",
    "            if one_step_transition:\n",
    "                self.memory.store(*one_step_transition)\n",
    "    \n",
    "        return next_state, reward, done\n",
    "\n",
    "    def update_model(self) -> torch.Tensor:\n",
    "        \"\"\"Update the model by gradient descent.\"\"\"\n",
    "        # PER needs beta to calculate weights\n",
    "        samples = self.memory.sample_batch(self.beta)\n",
    "        weights = torch.FloatTensor(\n",
    "            samples[\"weights\"].reshape(-1, 1)\n",
    "        ).to(self.device)\n",
    "        indices = samples[\"indices\"]\n",
    "        \n",
    "        # 1-step Learning loss\n",
    "        elementwise_loss = self._compute_dqn_loss(samples, self.gamma)\n",
    "        \n",
    "        # PER: importance sampling before average\n",
    "        loss = torch.mean(elementwise_loss * weights)\n",
    "        \n",
    "        # N-step Learning loss\n",
    "        # we are gonna combine 1-step loss and n-step loss so as to\n",
    "        # prevent high-variance. The original rainbow employs n-step loss only.\n",
    "        if self.use_n_step:\n",
    "            gamma = self.gamma ** self.n_step\n",
    "            samples = self.memory_n.sample_batch_from_idxs(indices)\n",
    "            elementwise_loss_n_loss = self._compute_dqn_loss(samples, gamma)\n",
    "            elementwise_loss += elementwise_loss_n_loss\n",
    "            \n",
    "            # PER: importance sampling before average\n",
    "            loss = torch.mean(elementwise_loss * weights)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(self.dqn.parameters(), 10.0)\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        # PER: update priorities\n",
    "        loss_for_prior = elementwise_loss.detach().cpu().numpy()\n",
    "        new_priorities = loss_for_prior + self.prior_eps\n",
    "        self.memory.update_priorities(indices, new_priorities)\n",
    "        \n",
    "        # NoisyNet: reset noise\n",
    "        self.dqn.reset_noise()\n",
    "        self.dqn_target.reset_noise()\n",
    "\n",
    "        return loss.item()\n",
    "        \n",
    "    def train(self, num_frames: int, plotting_interval: int = 200):\n",
    "        \"\"\"Train the agent.\"\"\"\n",
    "        self.is_test = False\n",
    "        \n",
    "        state, _ = self.env.reset(seed=self.seed)\n",
    "        update_cnt = 0\n",
    "        losses = []\n",
    "        scores = []\n",
    "        score = 0\n",
    "\n",
    "        for frame_idx in range(1, num_frames + 1):\n",
    "            action = self.select_action(state)\n",
    "            next_state, reward, done = self.step(action)\n",
    "\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            \n",
    "            # NoisyNet: removed decrease of epsilon\n",
    "            \n",
    "            # PER: increase beta\n",
    "            fraction = min(frame_idx / num_frames, 1.0)\n",
    "            self.beta = self.beta + fraction * (1.0 - self.beta)\n",
    "\n",
    "            # if episode ends\n",
    "            if done:\n",
    "                state, _ = self.env.reset(seed=self.seed)\n",
    "                scores.append(score)\n",
    "                score = 0\n",
    "\n",
    "            # if training is ready\n",
    "            if len(self.memory) >= self.batch_size:\n",
    "                loss = self.update_model()\n",
    "                losses.append(loss)\n",
    "                update_cnt += 1\n",
    "                \n",
    "                # if hard update is needed\n",
    "                if update_cnt % self.target_update == 0:\n",
    "                    self._target_hard_update()\n",
    "\n",
    "            # plotting\n",
    "            if frame_idx % plotting_interval == 0:\n",
    "                self._plot(frame_idx, scores, losses)\n",
    "                \n",
    "        self.env.close()\n",
    "                \n",
    "    def test(self, video_folder: str) -> None:\n",
    "        \"\"\"Test the agent.\"\"\"\n",
    "        self.is_test = True\n",
    "        \n",
    "        # for recording a video\n",
    "        naive_env = self.env\n",
    "        self.env = gym.wrappers.RecordVideo(self.env, video_folder=video_folder)\n",
    "        \n",
    "        state, _ = self.env.reset(seed=self.seed)\n",
    "        done = False\n",
    "        score = 0\n",
    "\n",
    "        iter = 0\n",
    "        \n",
    "        while not done:\n",
    "            iter += 1\n",
    "            if iter % 1000 == 0:\n",
    "                print(f'iter: {iter}, score: {score}')\n",
    "\n",
    "            action = self.select_action(state)\n",
    "            next_state, reward, done = self.step(action)\n",
    "\n",
    "            state = next_state\n",
    "            score += reward\n",
    "        \n",
    "        print(\"score: \", score)\n",
    "        self.env.close()\n",
    "        \n",
    "        # reset\n",
    "        self.env = naive_env\n",
    "\n",
    "    def _compute_dqn_loss(self, samples: Dict[str, np.ndarray], gamma: float) -> torch.Tensor:\n",
    "        \"\"\"Return categorical dqn loss.\"\"\"\n",
    "        device = self.device  # for shortening the following lines\n",
    "        state = torch.FloatTensor(samples[\"obs\"]).to(device)\n",
    "        next_state = torch.FloatTensor(samples[\"next_obs\"]).to(device)\n",
    "        action = torch.LongTensor(samples[\"acts\"]).to(device)\n",
    "        reward = torch.FloatTensor(samples[\"rews\"].reshape(-1, 1)).to(device)\n",
    "        done = torch.FloatTensor(samples[\"done\"].reshape(-1, 1)).to(device)\n",
    "        \n",
    "        # Categorical DQN algorithm\n",
    "        delta_z = float(self.v_max - self.v_min) / (self.atom_size - 1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Double DQN\n",
    "            next_action = self.dqn(next_state).argmax(1)\n",
    "            next_dist = self.dqn_target.dist(next_state)\n",
    "            next_dist = next_dist[range(self.batch_size), next_action]\n",
    "\n",
    "            t_z = reward + (1 - done) * gamma * self.support\n",
    "            t_z = t_z.clamp(min=self.v_min, max=self.v_max)\n",
    "            b = (t_z - self.v_min) / delta_z\n",
    "            l = b.floor().long()\n",
    "            u = b.ceil().long()\n",
    "\n",
    "            offset = (\n",
    "                torch.linspace(\n",
    "                    0, (self.batch_size - 1) * self.atom_size, self.batch_size\n",
    "                ).long()\n",
    "                .unsqueeze(1)\n",
    "                .expand(self.batch_size, self.atom_size)\n",
    "                .to(self.device)\n",
    "            )\n",
    "\n",
    "            proj_dist = torch.zeros(next_dist.size(), device=self.device)\n",
    "            proj_dist.view(-1).index_add_(\n",
    "                0, (l + offset).view(-1), (next_dist * (u.float() - b)).view(-1)\n",
    "            )\n",
    "            proj_dist.view(-1).index_add_(\n",
    "                0, (u + offset).view(-1), (next_dist * (b - l.float())).view(-1)\n",
    "            )\n",
    "\n",
    "        dist = self.dqn.dist(state)\n",
    "        log_p = torch.log(dist[range(self.batch_size), action])\n",
    "        elementwise_loss = -(proj_dist * log_p).sum(1)\n",
    "\n",
    "        return elementwise_loss\n",
    "\n",
    "    def _target_hard_update(self):\n",
    "        \"\"\"Hard update: target <- local.\"\"\"\n",
    "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
    "                \n",
    "    def _plot(\n",
    "        self, \n",
    "        frame_idx: int, \n",
    "        scores: List[float], \n",
    "        losses: List[float],\n",
    "    ):\n",
    "        \"\"\"Plot the training progresses.\"\"\"\n",
    "        clear_output(True)\n",
    "        plt.figure(figsize=(20, 5))\n",
    "        plt.subplot(131)\n",
    "        plt.title('frame %s. score: %s' % (frame_idx, np.mean(scores[-10:])))\n",
    "        plt.plot(scores)\n",
    "        plt.subplot(132)\n",
    "        plt.title('loss')\n",
    "        plt.plot(losses)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n",
    "\n",
    "You can see the [code](https://github.com/Farama-Foundation/Gymnasium/blob/main/gymnasium/envs/classic_control/cartpole.py) and [configurations](https://github.com/Farama-Foundation/Gymnasium/blob/main/gymnasium/envs/classic_control/cartpole.py#L91) of CartPole-v1 from Farama Gymnasium's repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment\n",
    "\n",
    "# env: gym.Env[Tuple[float, float, float, float], Literal[0, 1]] = gym.make(\"CartPole-v1\", max_episode_steps=200, render_mode=\"rgb_array\")\n",
    "\n",
    "from x2 import X2Env\n",
    "\n",
    "env = X2Env()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 777\n",
    "\n",
    "def seed_torch(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.backends.cudnn.enabled:\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "seed_torch(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 4\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "num_frames = 10000\n",
    "memory_size = 10000\n",
    "batch_size = 128\n",
    "target_update = 100\n",
    "\n",
    "# train\n",
    "agent = DQNAgent(env, memory_size, batch_size, target_update, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10.980707 10.958536 10.987301 10.969772]]\n",
      "[[11.028458 11.023034 11.026263 11.022543]]\n",
      "[[10.959097 10.951747 10.95931  10.943889]]\n",
      "[[11.041537 11.042781 11.060137 11.034791]]\n",
      "[[11.182539 11.176939 11.187383 11.17249 ]]\n",
      "[[11.227929 11.210019 11.228901 11.218382]]\n",
      "[[11.119145 11.101197 11.131052 11.112164]]\n",
      "[[11.1972475 11.193027  11.212725  11.189224 ]]\n",
      "[[11.163959 11.155221 11.172374 11.150984]]\n",
      "[[11.088781 11.071431 11.087465 11.072814]]\n",
      "[[10.934279 10.929009 10.936073 10.923508]]\n",
      "[[10.971168 10.967293 10.970308 10.963403]]\n",
      "[[11.13515  11.119167 11.139344 11.131406]]\n",
      "[[10.903283 10.90663  10.921714 10.915468]]\n",
      "[[11.013608 11.013646 11.032155 11.026071]]\n",
      "[[11.053716 11.042033 11.062668 11.046833]]\n",
      "[[10.965925  10.967255  10.978587  10.9709215]]\n",
      "[[11.106438 11.0978   11.110175 11.101518]]\n",
      "[[11.245947 11.240851 11.248207 11.249489]]\n",
      "[[11.096841 11.094205 11.10139  11.095558]]\n",
      "[[11.09471  11.081138 11.093859 11.095722]]\n",
      "[[11.102559 11.104785 11.112451 11.109756]]\n",
      "[[11.082262 11.078923 11.088786 11.08091 ]]\n",
      "[[11.009058 11.0085   11.020282 11.01847 ]]\n",
      "[[10.927082 10.91197  10.918784 10.917465]]\n",
      "[[10.966761 10.958648 10.95955  10.955741]]\n",
      "[[10.891476 10.889399 10.895654 10.899267]]\n",
      "[[10.92304  10.928914 10.919799 10.923527]]\n",
      "[[11.126855  11.1291275 11.146175  11.153431 ]]\n",
      "[[11.135469 11.1334   11.147784 11.139027]]\n",
      "[[11.110974 11.098329 11.103964 11.093949]]\n",
      "[[11.037034 11.031975 11.047851 11.050482]]\n",
      "[[11.043981 11.034997 11.044012 11.034145]]\n",
      "[[10.99041  10.992993 11.003207 10.989434]]\n",
      "[[11.047251 11.037802 11.047483 11.052448]]\n",
      "[[10.844432 10.84146  10.843376 10.847734]]\n",
      "[[10.892909 10.884976 10.884162 10.89214 ]]\n",
      "[[10.845177  10.846148  10.8434515 10.843483 ]]\n",
      "[[10.931997  10.9219475 10.937253  10.940188 ]]\n",
      "[[10.88463  10.877213 10.87916  10.888683]]\n",
      "[[10.97111  10.96864  10.96863  10.963968]]\n",
      "[[10.973199 10.967875 10.962766 10.974204]]\n",
      "[[10.981769 10.979896 10.982175 10.987433]]\n",
      "[[11.150237 11.141561 11.144416 11.155   ]]\n",
      "[[11.045055 11.034015 11.03437  11.044217]]\n",
      "[[11.009479 11.002893 11.004466 11.011376]]\n",
      "[[10.939866 10.934882 10.936587 10.940895]]\n",
      "[[10.981294 10.977008 10.970948 10.975583]]\n",
      "[[10.949394 10.942325 10.931064 10.945402]]\n",
      "[[10.844068  10.841268  10.8412485 10.839492 ]]\n",
      "[[10.80421  10.804638 10.795351 10.803159]]\n",
      "[[10.991824 10.995657 10.989632 10.988994]]\n",
      "[[10.961515 10.965628 10.959264 10.96157 ]]\n",
      "[[11.008265 11.004969 10.998987 11.005706]]\n",
      "[[10.892469 10.901357 10.889999 10.895491]]\n",
      "[[10.880065  10.888311  10.883821  10.8844795]]\n",
      "[[10.984805 10.9976   10.976629 10.976378]]\n",
      "[[10.982322 10.991927 10.979182 10.976996]]\n",
      "[[10.988213 11.00311  10.985163 10.986446]]\n",
      "[[11.159207 11.169338 11.161828 11.158099]]\n",
      "[[10.975066  10.9857645 10.975243  10.977039 ]]\n",
      "[[11.1014805 11.108603  11.096175  11.10405  ]]\n",
      "[[10.97883  10.986579 10.972201 10.977785]]\n",
      "[[10.754123 10.756283 10.754677 10.754999]]\n",
      "[[10.891632 10.898397 10.888024 10.891235]]\n",
      "[[11.05844  11.070962 11.055882 11.066703]]\n",
      "[[10.93833  10.950646 10.939388 10.936682]]\n",
      "[[10.909333 10.92091  10.913354 10.918265]]\n",
      "[[11.018401 11.022421 11.019192 11.019734]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb Cell 23\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m agent\u001b[39m.\u001b[39;49mtrain(num_frames)\n",
      "\u001b[1;32m/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb Cell 23\u001b[0m line \u001b[0;36m2\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=232'>233</a>\u001b[0m \u001b[39m# if training is ready\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=233'>234</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size:\n\u001b[0;32m--> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=234'>235</a>\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate_model()\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=235'>236</a>\u001b[0m     losses\u001b[39m.\u001b[39mappend(loss)\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=236'>237</a>\u001b[0m     update_cnt \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[1;32m/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb Cell 23\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=185'>186</a>\u001b[0m     loss \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmean(elementwise_loss \u001b[39m*\u001b[39m weights)\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=187'>188</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m--> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=188'>189</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=189'>190</a>\u001b[0m clip_grad_norm_(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdqn\u001b[39m.\u001b[39mparameters(), \u001b[39m10.0\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=190'>191</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/rainbow-is-all-you-need/.venv/lib/python3.8/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m~/rainbow-is-all-you-need/.venv/lib/python3.8/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "agent.train(num_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "Run the trained agent (1 episode)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guillaume/rainbow-is-all-you-need/.venv/lib/python3.8/site-packages/gymnasium/wrappers/record_video.py:87: UserWarning: \u001b[33mWARN: Overwriting existing videos at /home/guillaume/rainbow-is-all-you-need/videos/rainbow folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n",
      "/home/guillaume/rainbow-is-all-you-need/.venv/lib/python3.8/site-packages/gymnasium/wrappers/monitoring/video_recorder.py:62: UserWarning: \u001b[33mWARN: Disabling video recorder because environment <X2Env instance> was not initialized with any compatible video mode between `rgb_array` and `rgb_array_list`\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 1000, score: 6\n",
      "iter: 2000, score: 6\n",
      "iter: 3000, score: 6\n",
      "iter: 4000, score: 6\n",
      "iter: 5000, score: 6\n",
      "iter: 6000, score: 6\n",
      "iter: 7000, score: 6\n",
      "iter: 8000, score: 6\n",
      "iter: 9000, score: 6\n",
      "iter: 10000, score: 6\n",
      "iter: 11000, score: 6\n",
      "iter: 12000, score: 6\n",
      "iter: 13000, score: 6\n",
      "iter: 14000, score: 6\n",
      "iter: 15000, score: 6\n",
      "iter: 16000, score: 6\n",
      "iter: 17000, score: 6\n",
      "iter: 18000, score: 6\n",
      "iter: 19000, score: 6\n",
      "iter: 20000, score: 6\n",
      "iter: 21000, score: 6\n",
      "iter: 22000, score: 6\n",
      "iter: 23000, score: 6\n",
      "iter: 24000, score: 6\n",
      "iter: 25000, score: 6\n",
      "iter: 26000, score: 6\n",
      "iter: 27000, score: 6\n",
      "iter: 28000, score: 6\n",
      "iter: 29000, score: 6\n",
      "iter: 30000, score: 6\n",
      "iter: 31000, score: 6\n",
      "iter: 32000, score: 6\n",
      "iter: 33000, score: 6\n",
      "iter: 34000, score: 6\n",
      "iter: 35000, score: 6\n",
      "iter: 36000, score: 6\n",
      "iter: 37000, score: 6\n",
      "iter: 38000, score: 6\n",
      "iter: 39000, score: 6\n",
      "iter: 40000, score: 6\n",
      "iter: 41000, score: 6\n",
      "iter: 42000, score: 6\n",
      "iter: 43000, score: 6\n",
      "iter: 44000, score: 6\n",
      "iter: 45000, score: 6\n",
      "iter: 46000, score: 6\n",
      "iter: 47000, score: 6\n",
      "iter: 48000, score: 6\n",
      "iter: 49000, score: 6\n",
      "iter: 50000, score: 6\n",
      "iter: 51000, score: 6\n",
      "iter: 52000, score: 6\n",
      "iter: 53000, score: 6\n",
      "iter: 54000, score: 6\n",
      "iter: 55000, score: 6\n",
      "iter: 56000, score: 6\n",
      "iter: 57000, score: 6\n",
      "iter: 58000, score: 6\n",
      "iter: 59000, score: 6\n",
      "iter: 60000, score: 6\n",
      "iter: 61000, score: 6\n",
      "iter: 62000, score: 6\n",
      "iter: 63000, score: 6\n",
      "iter: 64000, score: 6\n",
      "iter: 65000, score: 6\n",
      "iter: 66000, score: 6\n",
      "iter: 67000, score: 6\n",
      "iter: 68000, score: 6\n",
      "iter: 69000, score: 6\n",
      "iter: 70000, score: 6\n",
      "iter: 71000, score: 6\n",
      "iter: 72000, score: 6\n",
      "iter: 73000, score: 6\n",
      "iter: 74000, score: 6\n",
      "iter: 75000, score: 6\n",
      "iter: 76000, score: 6\n",
      "iter: 77000, score: 6\n",
      "iter: 78000, score: 6\n",
      "iter: 79000, score: 6\n",
      "iter: 80000, score: 6\n",
      "iter: 81000, score: 6\n",
      "iter: 82000, score: 6\n",
      "iter: 83000, score: 6\n",
      "iter: 84000, score: 6\n",
      "iter: 85000, score: 6\n",
      "iter: 86000, score: 6\n",
      "iter: 87000, score: 6\n",
      "iter: 88000, score: 6\n",
      "iter: 89000, score: 6\n",
      "iter: 90000, score: 6\n",
      "iter: 91000, score: 6\n",
      "iter: 92000, score: 6\n",
      "iter: 93000, score: 6\n",
      "iter: 94000, score: 6\n",
      "iter: 95000, score: 6\n",
      "iter: 96000, score: 6\n",
      "iter: 97000, score: 6\n",
      "iter: 98000, score: 6\n",
      "iter: 99000, score: 6\n",
      "iter: 100000, score: 6\n",
      "iter: 101000, score: 6\n",
      "iter: 102000, score: 6\n",
      "iter: 103000, score: 6\n",
      "iter: 104000, score: 6\n",
      "iter: 105000, score: 6\n",
      "iter: 106000, score: 6\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb Cell 25\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m video_folder\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvideos/rainbow\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m agent\u001b[39m.\u001b[39;49mtest(video_folder\u001b[39m=\u001b[39;49mvideo_folder)\n",
      "\u001b[1;32m/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb Cell 25\u001b[0m line \u001b[0;36m2\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=260'>261</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39miter\u001b[39m \u001b[39m%\u001b[39m \u001b[39m1000\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=261'>262</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39miter: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39miter\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, score: \u001b[39m\u001b[39m{\u001b[39;00mscore\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=263'>264</a>\u001b[0m action \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mselect_action(state)\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=264'>265</a>\u001b[0m next_state, reward, done \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep(action)\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=266'>267</a>\u001b[0m state \u001b[39m=\u001b[39m next_state\n",
      "\u001b[1;32m/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb Cell 25\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=121'>122</a>\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Select an action from the input state.\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=122'>123</a>\u001b[0m \u001b[39m# NoisyNet: no epsilon greedy action selection\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=124'>125</a>\u001b[0m selected_action \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdqn(\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=125'>126</a>\u001b[0m     torch\u001b[39m.\u001b[39;49mFloatTensor(state)\u001b[39m.\u001b[39;49mto(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice)\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=126'>127</a>\u001b[0m )\u001b[39m.\u001b[39margmax()\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=128'>129</a>\u001b[0m selected_action \u001b[39m=\u001b[39m selected_action\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=130'>131</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_test:\n",
      "File \u001b[0;32m~/rainbow-is-all-you-need/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb Cell 25\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Forward method implementation.\"\"\"\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m     dist \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdist(x)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m     q \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msum(dist \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupport, dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m q\n",
      "\u001b[1;32m/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb Cell 25\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m val_hid \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalue_hidden_layer(feature))\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m advantage \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madvantage_layer(adv_hid)\u001b[39m.\u001b[39mview(\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m     \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout_dim, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39matom_size\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=45'>46</a>\u001b[0m value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalue_layer(val_hid)\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39matom_size)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=46'>47</a>\u001b[0m q_atoms \u001b[39m=\u001b[39m value \u001b[39m+\u001b[39m advantage \u001b[39m-\u001b[39m advantage\u001b[39m.\u001b[39mmean(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, keepdim\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=48'>49</a>\u001b[0m dist \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39msoftmax(q_atoms, dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/rainbow-is-all-you-need/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb Cell 25\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=65'>66</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=66'>67</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Forward method implementation.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=67'>68</a>\u001b[0m \u001b[39m    \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=68'>69</a>\u001b[0m \u001b[39m    We don't use separate statements on train / eval mode.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=69'>70</a>\u001b[0m \u001b[39m    It doesn't show remarkable difference of performance.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=70'>71</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=71'>72</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=72'>73</a>\u001b[0m         x,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=73'>74</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight_mu \u001b[39m+\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight_sigma \u001b[39m*\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight_epsilon,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=74'>75</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_mu \u001b[39m+\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_sigma \u001b[39m*\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_epsilon,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=75'>76</a>\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "video_folder=\"videos/rainbow\"\n",
    "agent.test(video_folder=video_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.is_test = True\n",
    "\n",
    "# naive_env = self.env\n",
    "        # self.env = gym.wrappers.RecordVideo(self.env, video_folder=video_folder)\n",
    "        \n",
    "state, _ = agent.env.reset(seed=agent.seed)\n",
    "done = False\n",
    "score = 0\n",
    "\n",
    "# iter = 0\n",
    "\n",
    "# while not done and iter < 1000:\n",
    "#     iter += 1\n",
    "#     if iter % 1000 == 0:\n",
    "#         print(f'iter: {iter}, score: {score}')\n",
    "\n",
    "#     action = agent.select_action(state)\n",
    "#     next_state, reward, done = agent.step(action)\n",
    "\n",
    "#     state = next_state\n",
    "#     score += reward\n",
    "\n",
    "# print(\"score: \", score)\n",
    "# agent.env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10.421991 10.426854 10.42357  10.422327]]\n",
      "1\n",
      "[[2 4 0 5 0]\n",
      " [4 3 0 4 0]\n",
      " [0 7 0 5 0]\n",
      " [0 4 0 1 0]\n",
      " [0 5 0 4 0]]\n",
      "-18\n"
     ]
    }
   ],
   "source": [
    "action = agent.select_action(state)\n",
    "next_state, reward, done = agent.step(action)\n",
    "print(action)\n",
    "print(next_state[1:].reshape(5, 5))\n",
    "\n",
    "state = next_state\n",
    "score += reward\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <video width=\"320\" height=\"240\" alt=\"test\" controls>\n",
       "        <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\"/>\n",
       "        </video>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Played: videos/rainbow/rl-video-episode-0.mp4\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import glob\n",
    "import io\n",
    "import os\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "\n",
    "def ipython_show_video(path: str) -> None:\n",
    "    \"\"\"Show a video at `path` within IPython Notebook.\"\"\"\n",
    "    if not os.path.isfile(path):\n",
    "        raise NameError(\"Cannot access: {}\".format(path))\n",
    "\n",
    "    video = io.open(path, \"r+b\").read()\n",
    "    encoded = base64.b64encode(video)\n",
    "\n",
    "    display(HTML(\n",
    "        data=\"\"\"\n",
    "        <video width=\"320\" height=\"240\" alt=\"test\" controls>\n",
    "        <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\"/>\n",
    "        </video>\n",
    "        \"\"\".format(encoded.decode(\"ascii\"))\n",
    "    ))\n",
    "\n",
    "\n",
    "def show_latest_video(video_folder: str) -> str:\n",
    "    \"\"\"Show the most recently recorded video from video folder.\"\"\"\n",
    "    list_of_files = glob.glob(os.path.join(video_folder, \"*.mp4\"))\n",
    "    latest_file = max(list_of_files, key=os.path.getctime)\n",
    "    ipython_show_video(latest_file)\n",
    "    return latest_file\n",
    "\n",
    "\n",
    "latest_file = show_latest_video(video_folder=video_folder)\n",
    "print(\"Played:\", latest_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
