{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations for Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    !apt install python-opengl\n",
    "    !apt install ffmpeg\n",
    "    !apt install xvfb\n",
    "    !pip install PyVirtualDisplay==3.0\n",
    "    !pip install gymnasium==0.28.1\n",
    "    from pyvirtualdisplay import Display\n",
    "    \n",
    "    # Start virtual display\n",
    "    dis = Display(visible=0, size=(400, 400))\n",
    "    dis.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08. Rainbow\n",
    "\n",
    "[M. Hessel et al., \"Rainbow: Combining Improvements in Deep Reinforcement Learning.\" arXiv preprint arXiv:1710.02298, 2017.](https://arxiv.org/pdf/1710.02298.pdf)\n",
    "\n",
    "We will integrate all the following seven components into a single integrated agent, which is called Rainbow!\n",
    "\n",
    "1. DQN\n",
    "2. Double DQN\n",
    "3. Prioritized Experience Replay\n",
    "4. Dueling Network\n",
    "5. Noisy Network\n",
    "6. Categorical DQN\n",
    "7. N-step Learning\n",
    "\n",
    "This method shows an impressive performance on the Atari 2600 benchmark, both in terms of data efficiency and final performance. \n",
    "\n",
    "![rainbow](https://user-images.githubusercontent.com/14961526/60591412-61748100-9dd9-11e9-84fb-076c7a61fbab.png)\n",
    "\n",
    "However, the integration is not so simple because some of components are not independent each other, so we will look into a number of points that people especailly feel confused.\n",
    "\n",
    "1. Noisy Network <-> Dueling Network\n",
    "2. Dueling Network <-> Categorical DQN\n",
    "3. Categorical DQN <-> Double DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guillaume/rainbow-is-all-you-need/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "from collections import deque\n",
    "from typing import Deque, Dict, List, Tuple\n",
    "\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from IPython.display import clear_output\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "# download segment tree module\n",
    "if IN_COLAB:\n",
    "    !wget https://raw.githubusercontent.com/curt-park/rainbow-is-all-you-need/master/segment_tree.py\n",
    "\n",
    "from segment_tree import MinSegmentTree, SumSegmentTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replay buffer\n",
    "\n",
    "Same as the basic N-step buffer. \n",
    "\n",
    "(Please see *01.dqn.ipynb*, *07.n_step_learning.ipynb* for detailed description about the basic (n-step) replay buffer.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"A simple numpy replay buffer.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        obs_dim: int, \n",
    "        size: int, \n",
    "        batch_size: int = 32, \n",
    "        n_step: int = 1, \n",
    "        gamma: float = 0.99\n",
    "    ):\n",
    "        self.obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "        self.next_obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "        self.acts_buf = np.zeros([size], dtype=np.float32)\n",
    "        self.rews_buf = np.zeros([size], dtype=np.float32)\n",
    "        self.done_buf = np.zeros(size, dtype=np.float32)\n",
    "        self.max_size, self.batch_size = size, batch_size\n",
    "        self.ptr, self.size, = 0, 0\n",
    "        \n",
    "        # for N-step Learning\n",
    "        self.n_step_buffer = deque(maxlen=n_step)\n",
    "        self.n_step = n_step\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def store(\n",
    "        self, \n",
    "        obs: np.ndarray, \n",
    "        act: np.ndarray, \n",
    "        rew: float, \n",
    "        next_obs: np.ndarray, \n",
    "        done: bool,\n",
    "    ) -> Tuple[np.ndarray, np.ndarray, float, np.ndarray, bool]:\n",
    "        transition = (obs, act, rew, next_obs, done)\n",
    "        self.n_step_buffer.append(transition)\n",
    "\n",
    "        # single step transition is not ready\n",
    "        if len(self.n_step_buffer) < self.n_step:\n",
    "            return ()\n",
    "        \n",
    "        # make a n-step transition\n",
    "        rew, next_obs, done = self._get_n_step_info(\n",
    "            self.n_step_buffer, self.gamma\n",
    "        )\n",
    "        obs, act = self.n_step_buffer[0][:2]\n",
    "        \n",
    "        self.obs_buf[self.ptr] = obs\n",
    "        self.next_obs_buf[self.ptr] = next_obs\n",
    "        self.acts_buf[self.ptr] = act\n",
    "        self.rews_buf[self.ptr] = rew\n",
    "        self.done_buf[self.ptr] = done\n",
    "        self.ptr = (self.ptr + 1) % self.max_size\n",
    "        self.size = min(self.size + 1, self.max_size)\n",
    "        \n",
    "        return self.n_step_buffer[0]\n",
    "\n",
    "    def sample_batch(self) -> Dict[str, np.ndarray]:\n",
    "        idxs = np.random.choice(self.size, size=self.batch_size, replace=False)\n",
    "\n",
    "        return dict(\n",
    "            obs=self.obs_buf[idxs],\n",
    "            next_obs=self.next_obs_buf[idxs],\n",
    "            acts=self.acts_buf[idxs],\n",
    "            rews=self.rews_buf[idxs],\n",
    "            done=self.done_buf[idxs],\n",
    "            # for N-step Learning\n",
    "            indices=idxs,\n",
    "        )\n",
    "    \n",
    "    def sample_batch_from_idxs(\n",
    "        self, idxs: np.ndarray\n",
    "    ) -> Dict[str, np.ndarray]:\n",
    "        # for N-step Learning\n",
    "        return dict(\n",
    "            obs=self.obs_buf[idxs],\n",
    "            next_obs=self.next_obs_buf[idxs],\n",
    "            acts=self.acts_buf[idxs],\n",
    "            rews=self.rews_buf[idxs],\n",
    "            done=self.done_buf[idxs],\n",
    "        )\n",
    "    \n",
    "    def _get_n_step_info(\n",
    "        self, n_step_buffer: Deque, gamma: float\n",
    "    ) -> Tuple[np.int64, np.ndarray, bool]:\n",
    "        \"\"\"Return n step rew, next_obs, and done.\"\"\"\n",
    "        # info of the last transition\n",
    "        rew, next_obs, done = n_step_buffer[-1][-3:]\n",
    "\n",
    "        for transition in reversed(list(n_step_buffer)[:-1]):\n",
    "            r, n_o, d = transition[-3:]\n",
    "\n",
    "            rew = r + gamma * rew * (1 - d)\n",
    "            next_obs, done = (n_o, d) if d else (next_obs, done)\n",
    "\n",
    "        return rew, next_obs, done\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prioritized replay Buffer\n",
    "\n",
    "`store` method returns boolean in order to inform if a N-step transition has been generated.\n",
    "\n",
    "(Please see *02.per.ipynb* for detailed description about PER.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrioritizedReplayBuffer(ReplayBuffer):\n",
    "    \"\"\"Prioritized Replay buffer.\n",
    "    \n",
    "    Attributes:\n",
    "        max_priority (float): max priority\n",
    "        tree_ptr (int): next index of tree\n",
    "        alpha (float): alpha parameter for prioritized replay buffer\n",
    "        sum_tree (SumSegmentTree): sum tree for prior\n",
    "        min_tree (MinSegmentTree): min tree for min prior to get max weight\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        obs_dim: int, \n",
    "        size: int, \n",
    "        batch_size: int = 32, \n",
    "        alpha: float = 0.6,\n",
    "        n_step: int = 1, \n",
    "        gamma: float = 0.99,\n",
    "    ):\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        assert alpha >= 0\n",
    "        \n",
    "        super(PrioritizedReplayBuffer, self).__init__(\n",
    "            obs_dim, size, batch_size, n_step, gamma\n",
    "        )\n",
    "        self.max_priority, self.tree_ptr = 1.0, 0\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        # capacity must be positive and a power of 2.\n",
    "        tree_capacity = 1\n",
    "        while tree_capacity < self.max_size:\n",
    "            tree_capacity *= 2\n",
    "\n",
    "        self.sum_tree = SumSegmentTree(tree_capacity)\n",
    "        self.min_tree = MinSegmentTree(tree_capacity)\n",
    "        \n",
    "    def store(\n",
    "        self, \n",
    "        obs: np.ndarray, \n",
    "        act: int, \n",
    "        rew: float, \n",
    "        next_obs: np.ndarray, \n",
    "        done: bool,\n",
    "    ) -> Tuple[np.ndarray, np.ndarray, float, np.ndarray, bool]:\n",
    "        \"\"\"Store experience and priority.\"\"\"\n",
    "        transition = super().store(obs, act, rew, next_obs, done)\n",
    "        \n",
    "        if transition:\n",
    "            self.sum_tree[self.tree_ptr] = self.max_priority ** self.alpha\n",
    "            self.min_tree[self.tree_ptr] = self.max_priority ** self.alpha\n",
    "            self.tree_ptr = (self.tree_ptr + 1) % self.max_size\n",
    "        \n",
    "        return transition\n",
    "\n",
    "    def sample_batch(self, beta: float = 0.4) -> Dict[str, np.ndarray]:\n",
    "        \"\"\"Sample a batch of experiences.\"\"\"\n",
    "        assert len(self) >= self.batch_size\n",
    "        assert beta > 0\n",
    "        \n",
    "        indices = self._sample_proportional()\n",
    "        \n",
    "        obs = self.obs_buf[indices]\n",
    "        next_obs = self.next_obs_buf[indices]\n",
    "        acts = self.acts_buf[indices]\n",
    "        rews = self.rews_buf[indices]\n",
    "        done = self.done_buf[indices]\n",
    "        weights = np.array([self._calculate_weight(i, beta) for i in indices])\n",
    "        \n",
    "        return dict(\n",
    "            obs=obs,\n",
    "            next_obs=next_obs,\n",
    "            acts=acts,\n",
    "            rews=rews,\n",
    "            done=done,\n",
    "            weights=weights,\n",
    "            indices=indices,\n",
    "        )\n",
    "        \n",
    "    def update_priorities(self, indices: List[int], priorities: np.ndarray):\n",
    "        \"\"\"Update priorities of sampled transitions.\"\"\"\n",
    "        assert len(indices) == len(priorities)\n",
    "\n",
    "        for idx, priority in zip(indices, priorities):\n",
    "            assert priority > 0\n",
    "            assert 0 <= idx < len(self)\n",
    "\n",
    "            self.sum_tree[idx] = priority ** self.alpha\n",
    "            self.min_tree[idx] = priority ** self.alpha\n",
    "\n",
    "            self.max_priority = max(self.max_priority, priority)\n",
    "            \n",
    "    def _sample_proportional(self) -> List[int]:\n",
    "        \"\"\"Sample indices based on proportions.\"\"\"\n",
    "        indices = []\n",
    "        p_total = self.sum_tree.sum(0, len(self) - 1)\n",
    "        segment = p_total / self.batch_size\n",
    "        \n",
    "        for i in range(self.batch_size):\n",
    "            a = segment * i\n",
    "            b = segment * (i + 1)\n",
    "            upperbound = random.uniform(a, b)\n",
    "            idx = self.sum_tree.retrieve(upperbound)\n",
    "            indices.append(idx)\n",
    "            \n",
    "        return indices\n",
    "    \n",
    "    def _calculate_weight(self, idx: int, beta: float):\n",
    "        \"\"\"Calculate the weight of the experience at idx.\"\"\"\n",
    "        # get max weight\n",
    "        p_min = self.min_tree.min() / self.sum_tree.sum()\n",
    "        max_weight = (p_min * len(self)) ** (-beta)\n",
    "        \n",
    "        # calculate weights\n",
    "        p_sample = self.sum_tree[idx] / self.sum_tree.sum()\n",
    "        weight = (p_sample * len(self)) ** (-beta)\n",
    "        weight = weight / max_weight\n",
    "        \n",
    "        return weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noisy Layer\n",
    "\n",
    "Please see *05.noisy_net.ipynb* for detailed description.\n",
    "\n",
    "**References:**\n",
    "\n",
    "- https://github.com/higgsfield/RL-Adventure/blob/master/5.noisy%20dqn.ipynb\n",
    "- https://github.com/Kaixhin/Rainbow/blob/master/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoisyLinear(nn.Module):\n",
    "    \"\"\"Noisy linear module for NoisyNet.\n",
    "    \n",
    "    \n",
    "        \n",
    "    Attributes:\n",
    "        in_features (int): input size of linear module\n",
    "        out_features (int): output size of linear module\n",
    "        std_init (float): initial std value\n",
    "        weight_mu (nn.Parameter): mean value weight parameter\n",
    "        weight_sigma (nn.Parameter): std value weight parameter\n",
    "        bias_mu (nn.Parameter): mean value bias parameter\n",
    "        bias_sigma (nn.Parameter): std value bias parameter\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_features: int, \n",
    "        out_features: int, \n",
    "        std_init: float = 0.5,\n",
    "    ):\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        super(NoisyLinear, self).__init__()\n",
    "        \n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.std_init = std_init\n",
    "\n",
    "        self.weight_mu = nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "        self.weight_sigma = nn.Parameter(\n",
    "            torch.Tensor(out_features, in_features)\n",
    "        )\n",
    "        self.register_buffer(\n",
    "            \"weight_epsilon\", torch.Tensor(out_features, in_features)\n",
    "        )\n",
    "\n",
    "        self.bias_mu = nn.Parameter(torch.Tensor(out_features))\n",
    "        self.bias_sigma = nn.Parameter(torch.Tensor(out_features))\n",
    "        self.register_buffer(\"bias_epsilon\", torch.Tensor(out_features))\n",
    "\n",
    "        self.reset_parameters()\n",
    "        self.reset_noise()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"Reset trainable network parameters (factorized gaussian noise).\"\"\"\n",
    "        mu_range = 1 / math.sqrt(self.in_features)\n",
    "        self.weight_mu.data.uniform_(-mu_range, mu_range)\n",
    "        self.weight_sigma.data.fill_(\n",
    "            self.std_init / math.sqrt(self.in_features)\n",
    "        )\n",
    "        self.bias_mu.data.uniform_(-mu_range, mu_range)\n",
    "        self.bias_sigma.data.fill_(\n",
    "            self.std_init / math.sqrt(self.out_features)\n",
    "        )\n",
    "\n",
    "    def reset_noise(self):\n",
    "        \"\"\"Make new noise.\"\"\"\n",
    "        epsilon_in = self.scale_noise(self.in_features)\n",
    "        epsilon_out = self.scale_noise(self.out_features)\n",
    "\n",
    "        # outer product\n",
    "        self.weight_epsilon.copy_(epsilon_out.ger(epsilon_in))\n",
    "        self.bias_epsilon.copy_(epsilon_out)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward method implementation.\n",
    "        \n",
    "        We don't use separate statements on train / eval mode.\n",
    "        It doesn't show remarkable difference of performance.\n",
    "        \"\"\"\n",
    "        return F.linear(\n",
    "            x,\n",
    "            self.weight_mu + self.weight_sigma * self.weight_epsilon,\n",
    "            self.bias_mu + self.bias_sigma * self.bias_epsilon,\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def scale_noise(size: int) -> torch.Tensor:\n",
    "        \"\"\"Set scale to make noise (factorized gaussian noise).\"\"\"\n",
    "        x = torch.randn(size)\n",
    "\n",
    "        return x.sign().mul(x.abs().sqrt())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NoisyNet + DuelingNet + Categorical DQN\n",
    "\n",
    "#### NoisyNet + DuelingNet\n",
    "\n",
    "NoisyLinear is employed for the last two layers of advantage and value layers. The noise should be reset at evey update step.\n",
    "\n",
    "#### DuelingNet + Categorical DQN\n",
    "\n",
    "The dueling network architecture is adapted for use with return distributions. The network has a shared representation, which is then fed into a value stream with atom_size outputs, and into an advantage stream with atom_size × out_dim outputs. For each atom, the value and advantage streams are aggregated, as in dueling DQN, and then passed through a softmax layer to obtain the normalized parametric distributions used to estimate the returns’ distributions.\n",
    "\n",
    "```\n",
    "        advantage = self.advantage_layer(adv_hid).view(-1, self.out_dim, self.atom_size)\n",
    "        value = self.value_layer(val_hid).view(-1, 1, self.atom_size)\n",
    "        q_atoms = value + advantage - advantage.mean(dim=1, keepdim=True)\n",
    "        \n",
    "        dist = F.softmax(q_atoms, dim=-1)\n",
    "```\n",
    "\n",
    "(Please see *04.dueling.ipynb*, *05.noisy_net.ipynb*, *06.categorical_dqn.ipynb* for detailed description of each component's network architecture.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_dim: int, \n",
    "        out_dim: int, \n",
    "        atom_size: int, \n",
    "        support: torch.Tensor\n",
    "    ):\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        super(Network, self).__init__()\n",
    "        \n",
    "        self.support = support\n",
    "        self.out_dim = out_dim\n",
    "        self.atom_size = atom_size\n",
    "\n",
    "        # set common feature layer\n",
    "        self.feature_layer = nn.Sequential(\n",
    "            nn.Linear(in_dim, 128), \n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # set advantage layer\n",
    "        self.advantage_hidden_layer = NoisyLinear(128, 128)\n",
    "        self.advantage_layer = NoisyLinear(128, out_dim * atom_size)\n",
    "\n",
    "        # set value layer\n",
    "        self.value_hidden_layer = NoisyLinear(128, 128)\n",
    "        self.value_layer = NoisyLinear(128, atom_size)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward method implementation.\"\"\"\n",
    "        dist = self.dist(x)\n",
    "        q = torch.sum(dist * self.support, dim=2)\n",
    "        \n",
    "        return q\n",
    "    \n",
    "    def dist(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Get distribution for atoms.\"\"\"\n",
    "        feature = self.feature_layer(x)\n",
    "        adv_hid = F.relu(self.advantage_hidden_layer(feature))\n",
    "        val_hid = F.relu(self.value_hidden_layer(feature))\n",
    "        \n",
    "        advantage = self.advantage_layer(adv_hid).view(\n",
    "            -1, self.out_dim, self.atom_size\n",
    "        )\n",
    "        value = self.value_layer(val_hid).view(-1, 1, self.atom_size)\n",
    "        q_atoms = value + advantage - advantage.mean(dim=1, keepdim=True)\n",
    "        \n",
    "        dist = F.softmax(q_atoms, dim=-1)\n",
    "        dist = dist.clamp(min=1e-3)  # for avoiding nans\n",
    "        \n",
    "        return dist\n",
    "    \n",
    "    def reset_noise(self):\n",
    "        \"\"\"Reset all noisy layers.\"\"\"\n",
    "        self.advantage_hidden_layer.reset_noise()\n",
    "        self.advantage_layer.reset_noise()\n",
    "        self.value_hidden_layer.reset_noise()\n",
    "        self.value_layer.reset_noise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rainbow Agent\n",
    "\n",
    "Here is a summary of DQNAgent class.\n",
    "\n",
    "| Method           | Note                                                 |\n",
    "| ---              | ---                                                  |\n",
    "|select_action     | select an action from the input state.               |\n",
    "|step              | take an action and return the response of the env.   |\n",
    "|compute_dqn_loss  | return dqn loss.                                     |\n",
    "|update_model      | update the model by gradient descent.                |\n",
    "|target_hard_update| hard update from the local model to the target model.|\n",
    "|train             | train the agent during num_frames.                   |\n",
    "|test              | test the agent (1 episode).                          |\n",
    "|plot              | plot the training progresses.                        |\n",
    "\n",
    "#### Categorical DQN + Double DQN\n",
    "\n",
    "The idea of Double Q-learning is to reduce overestimations by decomposing the max operation in the target into action selection and action evaluation. Here, we use `self.dqn` instead of `self.dqn_target` to obtain the target actions.\n",
    "\n",
    "```\n",
    "        # Categorical DQN + Double DQN\n",
    "        # target_dqn is used when we don't employ double DQN\n",
    "        next_action = self.dqn(next_state).argmax(1)\n",
    "        next_dist = self.dqn_target.dist(next_state)\n",
    "        next_dist = next_dist[range(self.batch_size), next_action]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    \"\"\"DQN Agent interacting with environment.\n",
    "    \n",
    "    Attribute:\n",
    "        env (gym.Env): openAI Gym environment\n",
    "        memory (PrioritizedReplayBuffer): replay memory to store transitions\n",
    "        batch_size (int): batch size for sampling\n",
    "        target_update (int): period for target model's hard update\n",
    "        gamma (float): discount factor\n",
    "        dqn (Network): model to train and select actions\n",
    "        dqn_target (Network): target model to update\n",
    "        optimizer (torch.optim): optimizer for training dqn\n",
    "        transition (list): transition information including \n",
    "                           state, action, reward, next_state, done\n",
    "        v_min (float): min value of support\n",
    "        v_max (float): max value of support\n",
    "        atom_size (int): the unit number of support\n",
    "        support (torch.Tensor): support for categorical dqn\n",
    "        use_n_step (bool): whether to use n_step memory\n",
    "        n_step (int): step number to calculate n-step td error\n",
    "        memory_n (ReplayBuffer): n-step replay buffer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        env: gym.Env,\n",
    "        memory_size: int,\n",
    "        batch_size: int,\n",
    "        target_update: int,\n",
    "        seed: int,\n",
    "        gamma: float = 0.99,\n",
    "        # PER parameters\n",
    "        alpha: float = 0.2,\n",
    "        beta: float = 0.6,\n",
    "        prior_eps: float = 1e-6,\n",
    "        # Categorical DQN parameters\n",
    "        v_min: float = 0.0,\n",
    "        v_max: float = 200.0,\n",
    "        atom_size: int = 51,\n",
    "        # N-step Learning\n",
    "        n_step: int = 3,\n",
    "    ):\n",
    "        \"\"\"Initialization.\n",
    "        \n",
    "        Args:\n",
    "            env (gym.Env): openAI Gym environment\n",
    "            memory_size (int): length of memory\n",
    "            batch_size (int): batch size for sampling\n",
    "            target_update (int): period for target model's hard update\n",
    "            lr (float): learning rate\n",
    "            gamma (float): discount factor\n",
    "            alpha (float): determines how much prioritization is used\n",
    "            beta (float): determines how much importance sampling is used\n",
    "            prior_eps (float): guarantees every transition can be sampled\n",
    "            v_min (float): min value of support\n",
    "            v_max (float): max value of support\n",
    "            atom_size (int): the unit number of support\n",
    "            n_step (int): step number to calculate n-step td error\n",
    "        \"\"\"\n",
    "        obs_dim = 26 #env.observation_space.shape[0]\n",
    "        action_dim = env.action_space.n\n",
    "\n",
    "        print(obs_dim, action_dim)\n",
    "        \n",
    "        self.env = env\n",
    "        self.batch_size = batch_size\n",
    "        self.target_update = target_update\n",
    "        self.seed = seed\n",
    "        self.gamma = gamma\n",
    "        # NoisyNet: All attributes related to epsilon are removed\n",
    "        \n",
    "        # device: cpu / gpu\n",
    "        self.device = torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "        print(self.device)\n",
    "        \n",
    "        # PER\n",
    "        # memory for 1-step Learning\n",
    "        self.beta = beta\n",
    "        self.prior_eps = prior_eps\n",
    "        self.memory = PrioritizedReplayBuffer(\n",
    "            obs_dim, memory_size, batch_size, alpha=alpha\n",
    "        )\n",
    "        \n",
    "        # memory for N-step Learning\n",
    "        self.use_n_step = True if n_step > 1 else False\n",
    "        if self.use_n_step:\n",
    "            self.n_step = n_step\n",
    "            self.memory_n = ReplayBuffer(\n",
    "                obs_dim, memory_size, batch_size, n_step=n_step, gamma=gamma\n",
    "            )\n",
    "            \n",
    "        # Categorical DQN parameters\n",
    "        self.v_min = v_min\n",
    "        self.v_max = v_max\n",
    "        self.atom_size = atom_size\n",
    "        self.support = torch.linspace(\n",
    "            self.v_min, self.v_max, self.atom_size\n",
    "        ).to(self.device)\n",
    "\n",
    "        # networks: dqn, dqn_target\n",
    "        self.dqn = Network(\n",
    "            obs_dim, action_dim, self.atom_size, self.support\n",
    "        ).to(self.device)\n",
    "        self.dqn_target = Network(\n",
    "            obs_dim, action_dim, self.atom_size, self.support\n",
    "        ).to(self.device)\n",
    "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
    "        self.dqn_target.eval()\n",
    "        \n",
    "        # optimizer\n",
    "        self.optimizer = optim.Adam(self.dqn.parameters())\n",
    "\n",
    "        # transition to store in memory\n",
    "        self.transition = list()\n",
    "        \n",
    "        # mode: train / test\n",
    "        self.is_test = False\n",
    "\n",
    "    def select_action(self, state: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Select an action from the input state.\"\"\"\n",
    "        # NoisyNet: no epsilon greedy action selection\n",
    "\n",
    "        selected_action = self.dqn(\n",
    "            torch.FloatTensor(state).to(self.device)\n",
    "        )\n",
    "\n",
    "        selected_action = selected_action.detach().cpu().numpy()\n",
    "\n",
    "        # print(selected_action)\n",
    "\n",
    "        selected_action = selected_action.argmax()\n",
    "        \n",
    "        if not self.is_test:\n",
    "            self.transition = [state, selected_action]\n",
    "\n",
    "        return selected_action\n",
    "\n",
    "    def step(self, action: np.ndarray) -> Tuple[np.ndarray, np.float64, bool]:\n",
    "        \"\"\"Take an action and return the response of the env.\"\"\"\n",
    "        next_state, reward, terminated, truncated, _ = self.env.step(action)\n",
    "        done = terminated or truncated\n",
    "        \n",
    "        if not self.is_test:\n",
    "            self.transition += [reward, next_state, done]\n",
    "            \n",
    "            # N-step transition\n",
    "            if self.use_n_step:\n",
    "                one_step_transition = self.memory_n.store(*self.transition)\n",
    "            # 1-step transition\n",
    "            else:\n",
    "                one_step_transition = self.transition\n",
    "\n",
    "            # add a single step transition\n",
    "            if one_step_transition:\n",
    "                self.memory.store(*one_step_transition)\n",
    "    \n",
    "        return next_state, reward, done\n",
    "\n",
    "    def update_model(self) -> torch.Tensor:\n",
    "        \"\"\"Update the model by gradient descent.\"\"\"\n",
    "        # PER needs beta to calculate weights\n",
    "        samples = self.memory.sample_batch(self.beta)\n",
    "        weights = torch.FloatTensor(\n",
    "            samples[\"weights\"].reshape(-1, 1)\n",
    "        ).to(self.device)\n",
    "        indices = samples[\"indices\"]\n",
    "        \n",
    "        # 1-step Learning loss\n",
    "        elementwise_loss = self._compute_dqn_loss(samples, self.gamma)\n",
    "        \n",
    "        # PER: importance sampling before average\n",
    "        loss = torch.mean(elementwise_loss * weights)\n",
    "        \n",
    "        # N-step Learning loss\n",
    "        # we are gonna combine 1-step loss and n-step loss so as to\n",
    "        # prevent high-variance. The original rainbow employs n-step loss only.\n",
    "        if self.use_n_step:\n",
    "            gamma = self.gamma ** self.n_step\n",
    "            samples = self.memory_n.sample_batch_from_idxs(indices)\n",
    "            elementwise_loss_n_loss = self._compute_dqn_loss(samples, gamma)\n",
    "            elementwise_loss += elementwise_loss_n_loss\n",
    "            \n",
    "            # PER: importance sampling before average\n",
    "            loss = torch.mean(elementwise_loss * weights)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(self.dqn.parameters(), 10.0)\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        # PER: update priorities\n",
    "        loss_for_prior = elementwise_loss.detach().cpu().numpy()\n",
    "        new_priorities = loss_for_prior + self.prior_eps\n",
    "        self.memory.update_priorities(indices, new_priorities)\n",
    "        \n",
    "        # NoisyNet: reset noise\n",
    "        self.dqn.reset_noise()\n",
    "        self.dqn_target.reset_noise()\n",
    "\n",
    "        return loss.item()\n",
    "        \n",
    "    def train(self, num_frames: int, plotting_interval: int = 200):\n",
    "        \"\"\"Train the agent.\"\"\"\n",
    "        self.is_test = False\n",
    "        \n",
    "        state, _ = self.env.reset(seed=self.seed)\n",
    "        update_cnt = 0\n",
    "        losses = []\n",
    "        scores = []\n",
    "        score = 0\n",
    "\n",
    "        for frame_idx in range(1, num_frames + 1):\n",
    "            action = self.select_action(state)\n",
    "            next_state, reward, done = self.step(action)\n",
    "\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            \n",
    "            # NoisyNet: removed decrease of epsilon\n",
    "            \n",
    "            # PER: increase beta\n",
    "            fraction = min(frame_idx / num_frames, 1.0)\n",
    "            self.beta = self.beta + fraction * (1.0 - self.beta)\n",
    "\n",
    "            # if episode ends\n",
    "            if done:\n",
    "                state, _ = self.env.reset(seed=self.seed)\n",
    "                scores.append(score)\n",
    "                score = 0\n",
    "\n",
    "            # if training is ready\n",
    "            if len(self.memory) >= self.batch_size:\n",
    "                loss = self.update_model()\n",
    "                losses.append(loss)\n",
    "                update_cnt += 1\n",
    "                \n",
    "                # if hard update is needed\n",
    "                if update_cnt % self.target_update == 0:\n",
    "                    self._target_hard_update()\n",
    "\n",
    "            # plotting\n",
    "            if frame_idx % plotting_interval == 0:\n",
    "                self._plot(frame_idx, scores, losses)\n",
    "                \n",
    "        self.env.close()\n",
    "                \n",
    "    def test(self, video_folder: str) -> None:\n",
    "        \"\"\"Test the agent.\"\"\"\n",
    "        self.is_test = True\n",
    "        \n",
    "        # for recording a video\n",
    "        naive_env = self.env\n",
    "        self.env = gym.wrappers.RecordVideo(self.env, video_folder=video_folder)\n",
    "        \n",
    "        state, _ = self.env.reset(seed=self.seed)\n",
    "        done = False\n",
    "        score = 0\n",
    "\n",
    "        iter = 0\n",
    "        \n",
    "        while not done:\n",
    "            iter += 1\n",
    "            if iter % 1000 == 0:\n",
    "                print(f'iter: {iter}, score: {score}')\n",
    "\n",
    "            action = self.select_action(state)\n",
    "            next_state, reward, done = self.step(action)\n",
    "\n",
    "            state = next_state\n",
    "            score += reward\n",
    "        \n",
    "        print(\"score: \", score)\n",
    "        self.env.close()\n",
    "        \n",
    "        # reset\n",
    "        self.env = naive_env\n",
    "\n",
    "    def _compute_dqn_loss(self, samples: Dict[str, np.ndarray], gamma: float) -> torch.Tensor:\n",
    "        \"\"\"Return categorical dqn loss.\"\"\"\n",
    "        device = self.device  # for shortening the following lines\n",
    "        state = torch.FloatTensor(samples[\"obs\"]).to(device)\n",
    "        next_state = torch.FloatTensor(samples[\"next_obs\"]).to(device)\n",
    "        action = torch.LongTensor(samples[\"acts\"]).to(device)\n",
    "        reward = torch.FloatTensor(samples[\"rews\"].reshape(-1, 1)).to(device)\n",
    "        done = torch.FloatTensor(samples[\"done\"].reshape(-1, 1)).to(device)\n",
    "        \n",
    "        # Categorical DQN algorithm\n",
    "        delta_z = float(self.v_max - self.v_min) / (self.atom_size - 1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Double DQN\n",
    "            next_action = self.dqn(next_state).argmax(1)\n",
    "            next_dist = self.dqn_target.dist(next_state)\n",
    "            next_dist = next_dist[range(self.batch_size), next_action]\n",
    "\n",
    "            t_z = reward + (1 - done) * gamma * self.support\n",
    "            t_z = t_z.clamp(min=self.v_min, max=self.v_max)\n",
    "            b = (t_z - self.v_min) / delta_z\n",
    "            l = b.floor().long()\n",
    "            u = b.ceil().long()\n",
    "\n",
    "            offset = (\n",
    "                torch.linspace(\n",
    "                    0, (self.batch_size - 1) * self.atom_size, self.batch_size\n",
    "                ).long()\n",
    "                .unsqueeze(1)\n",
    "                .expand(self.batch_size, self.atom_size)\n",
    "                .to(self.device)\n",
    "            )\n",
    "\n",
    "            proj_dist = torch.zeros(next_dist.size(), device=self.device)\n",
    "            proj_dist.view(-1).index_add_(\n",
    "                0, (l + offset).view(-1), (next_dist * (u.float() - b)).view(-1)\n",
    "            )\n",
    "            proj_dist.view(-1).index_add_(\n",
    "                0, (u + offset).view(-1), (next_dist * (b - l.float())).view(-1)\n",
    "            )\n",
    "\n",
    "        dist = self.dqn.dist(state)\n",
    "        log_p = torch.log(dist[range(self.batch_size), action])\n",
    "        elementwise_loss = -(proj_dist * log_p).sum(1)\n",
    "\n",
    "        return elementwise_loss\n",
    "\n",
    "    def _target_hard_update(self):\n",
    "        \"\"\"Hard update: target <- local.\"\"\"\n",
    "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
    "                \n",
    "    def _plot(\n",
    "        self, \n",
    "        frame_idx: int, \n",
    "        scores: List[float], \n",
    "        losses: List[float],\n",
    "    ):\n",
    "        \"\"\"Plot the training progresses.\"\"\"\n",
    "        clear_output(True)\n",
    "        plt.figure(figsize=(20, 5))\n",
    "        plt.subplot(131)\n",
    "        plt.title('frame %s. score: %s' % (frame_idx, np.mean(scores[-10:])))\n",
    "        plt.plot(scores)\n",
    "        plt.subplot(132)\n",
    "        plt.title('loss')\n",
    "        plt.plot(losses)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n",
    "\n",
    "You can see the [code](https://github.com/Farama-Foundation/Gymnasium/blob/main/gymnasium/envs/classic_control/cartpole.py) and [configurations](https://github.com/Farama-Foundation/Gymnasium/blob/main/gymnasium/envs/classic_control/cartpole.py#L91) of CartPole-v1 from Farama Gymnasium's repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment\n",
    "\n",
    "# env: gym.Env[Tuple[float, float, float, float], Literal[0, 1]] = gym.make(\"CartPole-v1\", max_episode_steps=200, render_mode=\"rgb_array\")\n",
    "\n",
    "from x2 import X2Env\n",
    "\n",
    "env = X2Env()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 777\n",
    "\n",
    "def seed_torch(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.backends.cudnn.enabled:\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "seed_torch(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 4\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "num_frames = 10000\n",
    "memory_size = 10000\n",
    "batch_size = 128\n",
    "target_update = 100\n",
    "\n",
    "# train\n",
    "agent = DQNAgent(env, memory_size, batch_size, target_update, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb Cell 23\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m agent\u001b[39m.\u001b[39;49mtrain(num_frames)\n",
      "\u001b[1;32m/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb Cell 23\u001b[0m line \u001b[0;36m2\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=232'>233</a>\u001b[0m \u001b[39m# if training is ready\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=233'>234</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size:\n\u001b[0;32m--> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=234'>235</a>\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate_model()\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=235'>236</a>\u001b[0m     losses\u001b[39m.\u001b[39mappend(loss)\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=236'>237</a>\u001b[0m     update_cnt \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[1;32m/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb Cell 23\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=167'>168</a>\u001b[0m indices \u001b[39m=\u001b[39m samples[\u001b[39m\"\u001b[39m\u001b[39mindices\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=169'>170</a>\u001b[0m \u001b[39m# 1-step Learning loss\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=170'>171</a>\u001b[0m elementwise_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compute_dqn_loss(samples, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgamma)\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=172'>173</a>\u001b[0m \u001b[39m# PER: importance sampling before average\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=173'>174</a>\u001b[0m loss \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmean(elementwise_loss \u001b[39m*\u001b[39m weights)\n",
      "\u001b[1;32m/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb Cell 23\u001b[0m line \u001b[0;36m2\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=283'>284</a>\u001b[0m next_state \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mFloatTensor(samples[\u001b[39m\"\u001b[39m\u001b[39mnext_obs\u001b[39m\u001b[39m\"\u001b[39m])\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=284'>285</a>\u001b[0m action \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mLongTensor(samples[\u001b[39m\"\u001b[39m\u001b[39macts\u001b[39m\u001b[39m\"\u001b[39m])\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m--> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=285'>286</a>\u001b[0m reward \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mFloatTensor(samples[\u001b[39m\"\u001b[39;49m\u001b[39mrews\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mreshape(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m))\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=286'>287</a>\u001b[0m done \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mFloatTensor(samples[\u001b[39m\"\u001b[39m\u001b[39mdone\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=288'>289</a>\u001b[0m \u001b[39m# Categorical DQN algorithm\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "agent.train(num_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "Run the trained agent (1 episode)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guillaume/rainbow-is-all-you-need/.venv/lib/python3.8/site-packages/gymnasium/wrappers/record_video.py:87: UserWarning: \u001b[33mWARN: Overwriting existing videos at /home/guillaume/rainbow-is-all-you-need/videos/rainbow folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n",
      "/home/guillaume/rainbow-is-all-you-need/.venv/lib/python3.8/site-packages/gymnasium/wrappers/monitoring/video_recorder.py:62: UserWarning: \u001b[33mWARN: Disabling video recorder because environment <X2Env instance> was not initialized with any compatible video mode between `rgb_array` and `rgb_array_list`\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 1000, score: 6\n",
      "iter: 2000, score: 6\n",
      "iter: 3000, score: 6\n",
      "iter: 4000, score: 6\n",
      "iter: 5000, score: 6\n",
      "iter: 6000, score: 6\n",
      "iter: 7000, score: 6\n",
      "iter: 8000, score: 6\n",
      "iter: 9000, score: 6\n",
      "iter: 10000, score: 6\n",
      "iter: 11000, score: 6\n",
      "iter: 12000, score: 6\n",
      "iter: 13000, score: 6\n",
      "iter: 14000, score: 6\n",
      "iter: 15000, score: 6\n",
      "iter: 16000, score: 6\n",
      "iter: 17000, score: 6\n",
      "iter: 18000, score: 6\n",
      "iter: 19000, score: 6\n",
      "iter: 20000, score: 6\n",
      "iter: 21000, score: 6\n",
      "iter: 22000, score: 6\n",
      "iter: 23000, score: 6\n",
      "iter: 24000, score: 6\n",
      "iter: 25000, score: 6\n",
      "iter: 26000, score: 6\n",
      "iter: 27000, score: 6\n",
      "iter: 28000, score: 6\n",
      "iter: 29000, score: 6\n",
      "iter: 30000, score: 6\n",
      "iter: 31000, score: 6\n",
      "iter: 32000, score: 6\n",
      "iter: 33000, score: 6\n",
      "iter: 34000, score: 6\n",
      "iter: 35000, score: 6\n",
      "iter: 36000, score: 6\n",
      "iter: 37000, score: 6\n",
      "iter: 38000, score: 6\n",
      "iter: 39000, score: 6\n",
      "iter: 40000, score: 6\n",
      "iter: 41000, score: 6\n",
      "iter: 42000, score: 6\n",
      "iter: 43000, score: 6\n",
      "iter: 44000, score: 6\n",
      "iter: 45000, score: 6\n",
      "iter: 46000, score: 6\n",
      "iter: 47000, score: 6\n",
      "iter: 48000, score: 6\n",
      "iter: 49000, score: 6\n",
      "iter: 50000, score: 6\n",
      "iter: 51000, score: 6\n",
      "iter: 52000, score: 6\n",
      "iter: 53000, score: 6\n",
      "iter: 54000, score: 6\n",
      "iter: 55000, score: 6\n",
      "iter: 56000, score: 6\n",
      "iter: 57000, score: 6\n",
      "iter: 58000, score: 6\n",
      "iter: 59000, score: 6\n",
      "iter: 60000, score: 6\n",
      "iter: 61000, score: 6\n",
      "iter: 62000, score: 6\n",
      "iter: 63000, score: 6\n",
      "iter: 64000, score: 6\n",
      "iter: 65000, score: 6\n",
      "iter: 66000, score: 6\n",
      "iter: 67000, score: 6\n",
      "iter: 68000, score: 6\n",
      "iter: 69000, score: 6\n",
      "iter: 70000, score: 6\n",
      "iter: 71000, score: 6\n",
      "iter: 72000, score: 6\n",
      "iter: 73000, score: 6\n",
      "iter: 74000, score: 6\n",
      "iter: 75000, score: 6\n",
      "iter: 76000, score: 6\n",
      "iter: 77000, score: 6\n",
      "iter: 78000, score: 6\n",
      "iter: 79000, score: 6\n",
      "iter: 80000, score: 6\n",
      "iter: 81000, score: 6\n",
      "iter: 82000, score: 6\n",
      "iter: 83000, score: 6\n",
      "iter: 84000, score: 6\n",
      "iter: 85000, score: 6\n",
      "iter: 86000, score: 6\n",
      "iter: 87000, score: 6\n",
      "iter: 88000, score: 6\n",
      "iter: 89000, score: 6\n",
      "iter: 90000, score: 6\n",
      "iter: 91000, score: 6\n",
      "iter: 92000, score: 6\n",
      "iter: 93000, score: 6\n",
      "iter: 94000, score: 6\n",
      "iter: 95000, score: 6\n",
      "iter: 96000, score: 6\n",
      "iter: 97000, score: 6\n",
      "iter: 98000, score: 6\n",
      "iter: 99000, score: 6\n",
      "iter: 100000, score: 6\n",
      "iter: 101000, score: 6\n",
      "iter: 102000, score: 6\n",
      "iter: 103000, score: 6\n",
      "iter: 104000, score: 6\n",
      "iter: 105000, score: 6\n",
      "iter: 106000, score: 6\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb Cell 25\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m video_folder\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvideos/rainbow\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m agent\u001b[39m.\u001b[39;49mtest(video_folder\u001b[39m=\u001b[39;49mvideo_folder)\n",
      "\u001b[1;32m/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb Cell 25\u001b[0m line \u001b[0;36m2\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=260'>261</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39miter\u001b[39m \u001b[39m%\u001b[39m \u001b[39m1000\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=261'>262</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39miter: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39miter\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, score: \u001b[39m\u001b[39m{\u001b[39;00mscore\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=263'>264</a>\u001b[0m action \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mselect_action(state)\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=264'>265</a>\u001b[0m next_state, reward, done \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep(action)\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=266'>267</a>\u001b[0m state \u001b[39m=\u001b[39m next_state\n",
      "\u001b[1;32m/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb Cell 25\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=121'>122</a>\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Select an action from the input state.\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=122'>123</a>\u001b[0m \u001b[39m# NoisyNet: no epsilon greedy action selection\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=124'>125</a>\u001b[0m selected_action \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdqn(\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=125'>126</a>\u001b[0m     torch\u001b[39m.\u001b[39;49mFloatTensor(state)\u001b[39m.\u001b[39;49mto(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice)\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=126'>127</a>\u001b[0m )\u001b[39m.\u001b[39margmax()\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=128'>129</a>\u001b[0m selected_action \u001b[39m=\u001b[39m selected_action\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=130'>131</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_test:\n",
      "File \u001b[0;32m~/rainbow-is-all-you-need/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb Cell 25\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Forward method implementation.\"\"\"\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m     dist \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdist(x)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m     q \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msum(dist \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupport, dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m q\n",
      "\u001b[1;32m/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb Cell 25\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m val_hid \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalue_hidden_layer(feature))\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m advantage \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madvantage_layer(adv_hid)\u001b[39m.\u001b[39mview(\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m     \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout_dim, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39matom_size\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=45'>46</a>\u001b[0m value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalue_layer(val_hid)\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39matom_size)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=46'>47</a>\u001b[0m q_atoms \u001b[39m=\u001b[39m value \u001b[39m+\u001b[39m advantage \u001b[39m-\u001b[39m advantage\u001b[39m.\u001b[39mmean(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, keepdim\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=48'>49</a>\u001b[0m dist \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39msoftmax(q_atoms, dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/rainbow-is-all-you-need/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb Cell 25\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=65'>66</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=66'>67</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Forward method implementation.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=67'>68</a>\u001b[0m \u001b[39m    \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=68'>69</a>\u001b[0m \u001b[39m    We don't use separate statements on train / eval mode.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=69'>70</a>\u001b[0m \u001b[39m    It doesn't show remarkable difference of performance.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=70'>71</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=71'>72</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=72'>73</a>\u001b[0m         x,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=73'>74</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight_mu \u001b[39m+\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight_sigma \u001b[39m*\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight_epsilon,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=74'>75</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_mu \u001b[39m+\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_sigma \u001b[39m*\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_epsilon,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=75'>76</a>\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "video_folder=\"videos/rainbow\"\n",
    "agent.test(video_folder=video_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.is_test = True\n",
    "\n",
    "# naive_env = self.env\n",
    "        # self.env = gym.wrappers.RecordVideo(self.env, video_folder=video_folder)\n",
    "        \n",
    "state, _ = agent.env.reset(seed=agent.seed)\n",
    "done = False\n",
    "score = 0\n",
    "\n",
    "# iter = 0\n",
    "\n",
    "# while not done and iter < 1000:\n",
    "#     iter += 1\n",
    "#     if iter % 1000 == 0:\n",
    "#         print(f'iter: {iter}, score: {score}')\n",
    "\n",
    "#     action = agent.select_action(state)\n",
    "#     next_state, reward, done = agent.step(action)\n",
    "\n",
    "#     state = next_state\n",
    "#     score += reward\n",
    "\n",
    "# print(\"score: \", score)\n",
    "# agent.env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.16666667, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[[0.         0.16666667 0.33333333 0.         0.        ]\n",
      " [0.         0.25       0.5        0.         0.        ]\n",
      " [0.         0.41666667 0.08333333 0.         0.        ]\n",
      " [0.         0.5        0.33333333 0.         0.        ]\n",
      " [0.         0.         0.41666667 0.         0.        ]]\n",
      "-10\n"
     ]
    }
   ],
   "source": [
    "action = agent.select_action(state)\n",
    "next_state, reward, done = agent.step(action)\n",
    "print(action)\n",
    "print(next_state[1:].reshape(5, 5))\n",
    "\n",
    "state = next_state\n",
    "score += reward\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <video width=\"320\" height=\"240\" alt=\"test\" controls>\n",
       "        <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\"/>\n",
       "        </video>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Played: videos/rainbow/rl-video-episode-0.mp4\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import glob\n",
    "import io\n",
    "import os\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "\n",
    "def ipython_show_video(path: str) -> None:\n",
    "    \"\"\"Show a video at `path` within IPython Notebook.\"\"\"\n",
    "    if not os.path.isfile(path):\n",
    "        raise NameError(\"Cannot access: {}\".format(path))\n",
    "\n",
    "    video = io.open(path, \"r+b\").read()\n",
    "    encoded = base64.b64encode(video)\n",
    "\n",
    "    display(HTML(\n",
    "        data=\"\"\"\n",
    "        <video width=\"320\" height=\"240\" alt=\"test\" controls>\n",
    "        <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\"/>\n",
    "        </video>\n",
    "        \"\"\".format(encoded.decode(\"ascii\"))\n",
    "    ))\n",
    "\n",
    "\n",
    "def show_latest_video(video_folder: str) -> str:\n",
    "    \"\"\"Show the most recently recorded video from video folder.\"\"\"\n",
    "    list_of_files = glob.glob(os.path.join(video_folder, \"*.mp4\"))\n",
    "    latest_file = max(list_of_files, key=os.path.getctime)\n",
    "    ipython_show_video(latest_file)\n",
    "    return latest_file\n",
    "\n",
    "\n",
    "latest_file = show_latest_video(video_folder=video_folder)\n",
    "print(\"Played:\", latest_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
