{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations for Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    !apt install python-opengl\n",
    "    !apt install ffmpeg\n",
    "    !apt install xvfb\n",
    "    !pip install PyVirtualDisplay==3.0\n",
    "    !pip install gymnasium==0.28.1\n",
    "    from pyvirtualdisplay import Display\n",
    "    \n",
    "    # Start virtual display\n",
    "    dis = Display(visible=0, size=(400, 400))\n",
    "    dis.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08. Rainbow\n",
    "\n",
    "[M. Hessel et al., \"Rainbow: Combining Improvements in Deep Reinforcement Learning.\" arXiv preprint arXiv:1710.02298, 2017.](https://arxiv.org/pdf/1710.02298.pdf)\n",
    "\n",
    "We will integrate all the following seven components into a single integrated agent, which is called Rainbow!\n",
    "\n",
    "1. DQN\n",
    "2. Double DQN\n",
    "3. Prioritized Experience Replay\n",
    "4. Dueling Network\n",
    "5. Noisy Network\n",
    "6. Categorical DQN\n",
    "7. N-step Learning\n",
    "\n",
    "This method shows an impressive performance on the Atari 2600 benchmark, both in terms of data efficiency and final performance. \n",
    "\n",
    "![rainbow](https://user-images.githubusercontent.com/14961526/60591412-61748100-9dd9-11e9-84fb-076c7a61fbab.png)\n",
    "\n",
    "However, the integration is not so simple because some of components are not independent each other, so we will look into a number of points that people especailly feel confused.\n",
    "\n",
    "1. Noisy Network <-> Dueling Network\n",
    "2. Dueling Network <-> Categorical DQN\n",
    "3. Categorical DQN <-> Double DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guillaume/rainbow-is-all-you-need/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "from collections import deque\n",
    "from typing import Deque, Dict, List, Tuple\n",
    "\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from IPython.display import clear_output\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "# download segment tree module\n",
    "if IN_COLAB:\n",
    "    !wget https://raw.githubusercontent.com/curt-park/rainbow-is-all-you-need/master/segment_tree.py\n",
    "\n",
    "from segment_tree import MinSegmentTree, SumSegmentTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replay buffer\n",
    "\n",
    "Same as the basic N-step buffer. \n",
    "\n",
    "(Please see *01.dqn.ipynb*, *07.n_step_learning.ipynb* for detailed description about the basic (n-step) replay buffer.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"A simple numpy replay buffer.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        obs_dim: int, \n",
    "        size: int, \n",
    "        batch_size: int = 32, \n",
    "        n_step: int = 1, \n",
    "        gamma: float = 0.99\n",
    "    ):\n",
    "        self.obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "        self.next_obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "        self.acts_buf = np.zeros([size], dtype=np.float32)\n",
    "        self.rews_buf = np.zeros([size], dtype=np.float32)\n",
    "        self.done_buf = np.zeros(size, dtype=np.float32)\n",
    "        self.max_size, self.batch_size = size, batch_size\n",
    "        self.ptr, self.size, = 0, 0\n",
    "        \n",
    "        # for N-step Learning\n",
    "        self.n_step_buffer = deque(maxlen=n_step)\n",
    "        self.n_step = n_step\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def store(\n",
    "        self, \n",
    "        obs: np.ndarray, \n",
    "        act: np.ndarray, \n",
    "        rew: float, \n",
    "        next_obs: np.ndarray, \n",
    "        done: bool,\n",
    "    ) -> Tuple[np.ndarray, np.ndarray, float, np.ndarray, bool]:\n",
    "        transition = (obs, act, rew, next_obs, done)\n",
    "        self.n_step_buffer.append(transition)\n",
    "\n",
    "        # single step transition is not ready\n",
    "        if len(self.n_step_buffer) < self.n_step:\n",
    "            return ()\n",
    "        \n",
    "        # make a n-step transition\n",
    "        rew, next_obs, done = self._get_n_step_info(\n",
    "            self.n_step_buffer, self.gamma\n",
    "        )\n",
    "        obs, act = self.n_step_buffer[0][:2]\n",
    "        \n",
    "        self.obs_buf[self.ptr] = obs\n",
    "        self.next_obs_buf[self.ptr] = next_obs\n",
    "        self.acts_buf[self.ptr] = act\n",
    "        self.rews_buf[self.ptr] = rew\n",
    "        self.done_buf[self.ptr] = done\n",
    "        self.ptr = (self.ptr + 1) % self.max_size\n",
    "        self.size = min(self.size + 1, self.max_size)\n",
    "        \n",
    "        return self.n_step_buffer[0]\n",
    "\n",
    "    def sample_batch(self) -> Dict[str, np.ndarray]:\n",
    "        idxs = np.random.choice(self.size, size=self.batch_size, replace=False)\n",
    "\n",
    "        return dict(\n",
    "            obs=self.obs_buf[idxs],\n",
    "            next_obs=self.next_obs_buf[idxs],\n",
    "            acts=self.acts_buf[idxs],\n",
    "            rews=self.rews_buf[idxs],\n",
    "            done=self.done_buf[idxs],\n",
    "            # for N-step Learning\n",
    "            indices=idxs,\n",
    "        )\n",
    "    \n",
    "    def sample_batch_from_idxs(\n",
    "        self, idxs: np.ndarray\n",
    "    ) -> Dict[str, np.ndarray]:\n",
    "        # for N-step Learning\n",
    "        return dict(\n",
    "            obs=self.obs_buf[idxs],\n",
    "            next_obs=self.next_obs_buf[idxs],\n",
    "            acts=self.acts_buf[idxs],\n",
    "            rews=self.rews_buf[idxs],\n",
    "            done=self.done_buf[idxs],\n",
    "        )\n",
    "    \n",
    "    def _get_n_step_info(\n",
    "        self, n_step_buffer: Deque, gamma: float\n",
    "    ) -> Tuple[np.int64, np.ndarray, bool]:\n",
    "        \"\"\"Return n step rew, next_obs, and done.\"\"\"\n",
    "        # info of the last transition\n",
    "        rew, next_obs, done = n_step_buffer[-1][-3:]\n",
    "\n",
    "        for transition in reversed(list(n_step_buffer)[:-1]):\n",
    "            r, n_o, d = transition[-3:]\n",
    "\n",
    "            rew = r + gamma * rew * (1 - d)\n",
    "            next_obs, done = (n_o, d) if d else (next_obs, done)\n",
    "\n",
    "        return rew, next_obs, done\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prioritized replay Buffer\n",
    "\n",
    "`store` method returns boolean in order to inform if a N-step transition has been generated.\n",
    "\n",
    "(Please see *02.per.ipynb* for detailed description about PER.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrioritizedReplayBuffer(ReplayBuffer):\n",
    "    \"\"\"Prioritized Replay buffer.\n",
    "    \n",
    "    Attributes:\n",
    "        max_priority (float): max priority\n",
    "        tree_ptr (int): next index of tree\n",
    "        alpha (float): alpha parameter for prioritized replay buffer\n",
    "        sum_tree (SumSegmentTree): sum tree for prior\n",
    "        min_tree (MinSegmentTree): min tree for min prior to get max weight\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        obs_dim: int, \n",
    "        size: int, \n",
    "        batch_size: int = 32, \n",
    "        alpha: float = 0.6,\n",
    "        n_step: int = 1, \n",
    "        gamma: float = 0.99,\n",
    "    ):\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        assert alpha >= 0\n",
    "        \n",
    "        super(PrioritizedReplayBuffer, self).__init__(\n",
    "            obs_dim, size, batch_size, n_step, gamma\n",
    "        )\n",
    "        self.max_priority, self.tree_ptr = 1.0, 0\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        # capacity must be positive and a power of 2.\n",
    "        tree_capacity = 1\n",
    "        while tree_capacity < self.max_size:\n",
    "            tree_capacity *= 2\n",
    "\n",
    "        self.sum_tree = SumSegmentTree(tree_capacity)\n",
    "        self.min_tree = MinSegmentTree(tree_capacity)\n",
    "        \n",
    "    def store(\n",
    "        self, \n",
    "        obs: np.ndarray, \n",
    "        act: int, \n",
    "        rew: float, \n",
    "        next_obs: np.ndarray, \n",
    "        done: bool,\n",
    "    ) -> Tuple[np.ndarray, np.ndarray, float, np.ndarray, bool]:\n",
    "        \"\"\"Store experience and priority.\"\"\"\n",
    "        transition = super().store(obs, act, rew, next_obs, done)\n",
    "        \n",
    "        if transition:\n",
    "            self.sum_tree[self.tree_ptr] = self.max_priority ** self.alpha\n",
    "            self.min_tree[self.tree_ptr] = self.max_priority ** self.alpha\n",
    "            self.tree_ptr = (self.tree_ptr + 1) % self.max_size\n",
    "        \n",
    "        return transition\n",
    "\n",
    "    def sample_batch(self, beta: float = 0.4) -> Dict[str, np.ndarray]:\n",
    "        \"\"\"Sample a batch of experiences.\"\"\"\n",
    "        assert len(self) >= self.batch_size\n",
    "        assert beta > 0\n",
    "        \n",
    "        indices = self._sample_proportional()\n",
    "        \n",
    "        obs = self.obs_buf[indices]\n",
    "        next_obs = self.next_obs_buf[indices]\n",
    "        acts = self.acts_buf[indices]\n",
    "        rews = self.rews_buf[indices]\n",
    "        done = self.done_buf[indices]\n",
    "        weights = np.array([self._calculate_weight(i, beta) for i in indices])\n",
    "        \n",
    "        return dict(\n",
    "            obs=obs,\n",
    "            next_obs=next_obs,\n",
    "            acts=acts,\n",
    "            rews=rews,\n",
    "            done=done,\n",
    "            weights=weights,\n",
    "            indices=indices,\n",
    "        )\n",
    "        \n",
    "    def update_priorities(self, indices: List[int], priorities: np.ndarray):\n",
    "        \"\"\"Update priorities of sampled transitions.\"\"\"\n",
    "        assert len(indices) == len(priorities)\n",
    "\n",
    "        for idx, priority in zip(indices, priorities):\n",
    "            assert priority > 0\n",
    "            assert 0 <= idx < len(self)\n",
    "\n",
    "            self.sum_tree[idx] = priority ** self.alpha\n",
    "            self.min_tree[idx] = priority ** self.alpha\n",
    "\n",
    "            self.max_priority = max(self.max_priority, priority)\n",
    "            \n",
    "    def _sample_proportional(self) -> List[int]:\n",
    "        \"\"\"Sample indices based on proportions.\"\"\"\n",
    "        indices = []\n",
    "        p_total = self.sum_tree.sum(0, len(self) - 1)\n",
    "        segment = p_total / self.batch_size\n",
    "        \n",
    "        for i in range(self.batch_size):\n",
    "            a = segment * i\n",
    "            b = segment * (i + 1)\n",
    "            upperbound = random.uniform(a, b)\n",
    "            idx = self.sum_tree.retrieve(upperbound)\n",
    "            indices.append(idx)\n",
    "            \n",
    "        return indices\n",
    "    \n",
    "    def _calculate_weight(self, idx: int, beta: float):\n",
    "        \"\"\"Calculate the weight of the experience at idx.\"\"\"\n",
    "        # get max weight\n",
    "        p_min = self.min_tree.min() / self.sum_tree.sum()\n",
    "        max_weight = (p_min * len(self)) ** (-beta)\n",
    "        \n",
    "        # calculate weights\n",
    "        p_sample = self.sum_tree[idx] / self.sum_tree.sum()\n",
    "        weight = (p_sample * len(self)) ** (-beta)\n",
    "        weight = weight / max_weight\n",
    "        \n",
    "        return weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noisy Layer\n",
    "\n",
    "Please see *05.noisy_net.ipynb* for detailed description.\n",
    "\n",
    "**References:**\n",
    "\n",
    "- https://github.com/higgsfield/RL-Adventure/blob/master/5.noisy%20dqn.ipynb\n",
    "- https://github.com/Kaixhin/Rainbow/blob/master/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoisyLinear(nn.Module):\n",
    "    \"\"\"Noisy linear module for NoisyNet.\n",
    "    \n",
    "    \n",
    "        \n",
    "    Attributes:\n",
    "        in_features (int): input size of linear module\n",
    "        out_features (int): output size of linear module\n",
    "        std_init (float): initial std value\n",
    "        weight_mu (nn.Parameter): mean value weight parameter\n",
    "        weight_sigma (nn.Parameter): std value weight parameter\n",
    "        bias_mu (nn.Parameter): mean value bias parameter\n",
    "        bias_sigma (nn.Parameter): std value bias parameter\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_features: int, \n",
    "        out_features: int, \n",
    "        std_init: float = 0.5,\n",
    "    ):\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        super(NoisyLinear, self).__init__()\n",
    "        \n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.std_init = std_init\n",
    "\n",
    "        self.weight_mu = nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "        self.weight_sigma = nn.Parameter(\n",
    "            torch.Tensor(out_features, in_features)\n",
    "        )\n",
    "        self.register_buffer(\n",
    "            \"weight_epsilon\", torch.Tensor(out_features, in_features)\n",
    "        )\n",
    "\n",
    "        self.bias_mu = nn.Parameter(torch.Tensor(out_features))\n",
    "        self.bias_sigma = nn.Parameter(torch.Tensor(out_features))\n",
    "        self.register_buffer(\"bias_epsilon\", torch.Tensor(out_features))\n",
    "\n",
    "        self.reset_parameters()\n",
    "        self.reset_noise()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"Reset trainable network parameters (factorized gaussian noise).\"\"\"\n",
    "        mu_range = 1 / math.sqrt(self.in_features)\n",
    "        self.weight_mu.data.uniform_(-mu_range, mu_range)\n",
    "        self.weight_sigma.data.fill_(\n",
    "            self.std_init / math.sqrt(self.in_features)\n",
    "        )\n",
    "        self.bias_mu.data.uniform_(-mu_range, mu_range)\n",
    "        self.bias_sigma.data.fill_(\n",
    "            self.std_init / math.sqrt(self.out_features)\n",
    "        )\n",
    "\n",
    "    def reset_noise(self):\n",
    "        \"\"\"Make new noise.\"\"\"\n",
    "        epsilon_in = self.scale_noise(self.in_features)\n",
    "        epsilon_out = self.scale_noise(self.out_features)\n",
    "\n",
    "        # outer product\n",
    "        self.weight_epsilon.copy_(epsilon_out.ger(epsilon_in))\n",
    "        self.bias_epsilon.copy_(epsilon_out)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward method implementation.\n",
    "        \n",
    "        We don't use separate statements on train / eval mode.\n",
    "        It doesn't show remarkable difference of performance.\n",
    "        \"\"\"\n",
    "        return F.linear(\n",
    "            x,\n",
    "            self.weight_mu + self.weight_sigma * self.weight_epsilon,\n",
    "            self.bias_mu + self.bias_sigma * self.bias_epsilon,\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def scale_noise(size: int) -> torch.Tensor:\n",
    "        \"\"\"Set scale to make noise (factorized gaussian noise).\"\"\"\n",
    "        x = torch.randn(size)\n",
    "\n",
    "        return x.sign().mul(x.abs().sqrt())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NoisyNet + DuelingNet + Categorical DQN\n",
    "\n",
    "#### NoisyNet + DuelingNet\n",
    "\n",
    "NoisyLinear is employed for the last two layers of advantage and value layers. The noise should be reset at evey update step.\n",
    "\n",
    "#### DuelingNet + Categorical DQN\n",
    "\n",
    "The dueling network architecture is adapted for use with return distributions. The network has a shared representation, which is then fed into a value stream with atom_size outputs, and into an advantage stream with atom_size × out_dim outputs. For each atom, the value and advantage streams are aggregated, as in dueling DQN, and then passed through a softmax layer to obtain the normalized parametric distributions used to estimate the returns’ distributions.\n",
    "\n",
    "```\n",
    "        advantage = self.advantage_layer(adv_hid).view(-1, self.out_dim, self.atom_size)\n",
    "        value = self.value_layer(val_hid).view(-1, 1, self.atom_size)\n",
    "        q_atoms = value + advantage - advantage.mean(dim=1, keepdim=True)\n",
    "        \n",
    "        dist = F.softmax(q_atoms, dim=-1)\n",
    "```\n",
    "\n",
    "(Please see *04.dueling.ipynb*, *05.noisy_net.ipynb*, *06.categorical_dqn.ipynb* for detailed description of each component's network architecture.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_dim: int, \n",
    "        out_dim: int, \n",
    "        atom_size: int, \n",
    "        support: torch.Tensor\n",
    "    ):\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        super(Network, self).__init__()\n",
    "        \n",
    "        self.support = support\n",
    "        self.out_dim = out_dim\n",
    "        self.atom_size = atom_size\n",
    "\n",
    "        # set common feature layer\n",
    "        self.feature_layer = nn.Sequential(\n",
    "            nn.Linear(in_dim, 128), \n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # set advantage layer\n",
    "        self.advantage_hidden_layer = NoisyLinear(128, 128)\n",
    "        self.advantage_layer = NoisyLinear(128, out_dim * atom_size)\n",
    "\n",
    "        # set value layer\n",
    "        self.value_hidden_layer = NoisyLinear(128, 128)\n",
    "        self.value_layer = NoisyLinear(128, atom_size)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward method implementation.\"\"\"\n",
    "        dist = self.dist(x)\n",
    "        q = torch.sum(dist * self.support, dim=2)\n",
    "        \n",
    "        return q\n",
    "    \n",
    "    def dist(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Get distribution for atoms.\"\"\"\n",
    "        feature = self.feature_layer(x)\n",
    "        adv_hid = F.relu(self.advantage_hidden_layer(feature))\n",
    "        val_hid = F.relu(self.value_hidden_layer(feature))\n",
    "        \n",
    "        advantage = self.advantage_layer(adv_hid).view(\n",
    "            -1, self.out_dim, self.atom_size\n",
    "        )\n",
    "        value = self.value_layer(val_hid).view(-1, 1, self.atom_size)\n",
    "        q_atoms = value + advantage - advantage.mean(dim=1, keepdim=True)\n",
    "        \n",
    "        dist = F.softmax(q_atoms, dim=-1)\n",
    "        dist = dist.clamp(min=1e-3)  # for avoiding nans\n",
    "        \n",
    "        return dist\n",
    "    \n",
    "    def reset_noise(self):\n",
    "        \"\"\"Reset all noisy layers.\"\"\"\n",
    "        self.advantage_hidden_layer.reset_noise()\n",
    "        self.advantage_layer.reset_noise()\n",
    "        self.value_hidden_layer.reset_noise()\n",
    "        self.value_layer.reset_noise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rainbow Agent\n",
    "\n",
    "Here is a summary of DQNAgent class.\n",
    "\n",
    "| Method           | Note                                                 |\n",
    "| ---              | ---                                                  |\n",
    "|select_action     | select an action from the input state.               |\n",
    "|step              | take an action and return the response of the env.   |\n",
    "|compute_dqn_loss  | return dqn loss.                                     |\n",
    "|update_model      | update the model by gradient descent.                |\n",
    "|target_hard_update| hard update from the local model to the target model.|\n",
    "|train             | train the agent during num_frames.                   |\n",
    "|test              | test the agent (1 episode).                          |\n",
    "|plot              | plot the training progresses.                        |\n",
    "\n",
    "#### Categorical DQN + Double DQN\n",
    "\n",
    "The idea of Double Q-learning is to reduce overestimations by decomposing the max operation in the target into action selection and action evaluation. Here, we use `self.dqn` instead of `self.dqn_target` to obtain the target actions.\n",
    "\n",
    "```\n",
    "        # Categorical DQN + Double DQN\n",
    "        # target_dqn is used when we don't employ double DQN\n",
    "        next_action = self.dqn(next_state).argmax(1)\n",
    "        next_dist = self.dqn_target.dist(next_state)\n",
    "        next_dist = next_dist[range(self.batch_size), next_action]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    \"\"\"DQN Agent interacting with environment.\n",
    "    \n",
    "    Attribute:\n",
    "        env (gym.Env): openAI Gym environment\n",
    "        memory (PrioritizedReplayBuffer): replay memory to store transitions\n",
    "        batch_size (int): batch size for sampling\n",
    "        target_update (int): period for target model's hard update\n",
    "        gamma (float): discount factor\n",
    "        dqn (Network): model to train and select actions\n",
    "        dqn_target (Network): target model to update\n",
    "        optimizer (torch.optim): optimizer for training dqn\n",
    "        transition (list): transition information including \n",
    "                           state, action, reward, next_state, done\n",
    "        v_min (float): min value of support\n",
    "        v_max (float): max value of support\n",
    "        atom_size (int): the unit number of support\n",
    "        support (torch.Tensor): support for categorical dqn\n",
    "        use_n_step (bool): whether to use n_step memory\n",
    "        n_step (int): step number to calculate n-step td error\n",
    "        memory_n (ReplayBuffer): n-step replay buffer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        env: gym.Env,\n",
    "        memory_size: int,\n",
    "        batch_size: int,\n",
    "        target_update: int,\n",
    "        seed: int,\n",
    "        gamma: float = 0.99,\n",
    "        # PER parameters\n",
    "        alpha: float = 0.2,\n",
    "        beta: float = 0.6,\n",
    "        prior_eps: float = 1e-6,\n",
    "        # Categorical DQN parameters\n",
    "        v_min: float = 0.0,\n",
    "        v_max: float = 200.0,\n",
    "        atom_size: int = 51,\n",
    "        # N-step Learning\n",
    "        n_step: int = 3,\n",
    "    ):\n",
    "        \"\"\"Initialization.\n",
    "        \n",
    "        Args:\n",
    "            env (gym.Env): openAI Gym environment\n",
    "            memory_size (int): length of memory\n",
    "            batch_size (int): batch size for sampling\n",
    "            target_update (int): period for target model's hard update\n",
    "            lr (float): learning rate\n",
    "            gamma (float): discount factor\n",
    "            alpha (float): determines how much prioritization is used\n",
    "            beta (float): determines how much importance sampling is used\n",
    "            prior_eps (float): guarantees every transition can be sampled\n",
    "            v_min (float): min value of support\n",
    "            v_max (float): max value of support\n",
    "            atom_size (int): the unit number of support\n",
    "            n_step (int): step number to calculate n-step td error\n",
    "        \"\"\"\n",
    "        obs_dim = 26 #env.observation_space.shape[0]\n",
    "        action_dim = env.action_space.n\n",
    "\n",
    "        print(obs_dim, action_dim)\n",
    "        \n",
    "        self.env = env\n",
    "        self.batch_size = batch_size\n",
    "        self.target_update = target_update\n",
    "        self.seed = seed\n",
    "        self.gamma = gamma\n",
    "        # NoisyNet: All attributes related to epsilon are removed\n",
    "        \n",
    "        # device: cpu / gpu\n",
    "        self.device = torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "        print(self.device)\n",
    "        \n",
    "        # PER\n",
    "        # memory for 1-step Learning\n",
    "        self.beta = beta\n",
    "        self.prior_eps = prior_eps\n",
    "        self.memory = PrioritizedReplayBuffer(\n",
    "            obs_dim, memory_size, batch_size, alpha=alpha\n",
    "        )\n",
    "        \n",
    "        # memory for N-step Learning\n",
    "        self.use_n_step = True if n_step > 1 else False\n",
    "        if self.use_n_step:\n",
    "            self.n_step = n_step\n",
    "            self.memory_n = ReplayBuffer(\n",
    "                obs_dim, memory_size, batch_size, n_step=n_step, gamma=gamma\n",
    "            )\n",
    "            \n",
    "        # Categorical DQN parameters\n",
    "        self.v_min = v_min\n",
    "        self.v_max = v_max\n",
    "        self.atom_size = atom_size\n",
    "        self.support = torch.linspace(\n",
    "            self.v_min, self.v_max, self.atom_size\n",
    "        ).to(self.device)\n",
    "\n",
    "        # networks: dqn, dqn_target\n",
    "        self.dqn = Network(\n",
    "            obs_dim, action_dim, self.atom_size, self.support\n",
    "        ).to(self.device)\n",
    "        self.dqn_target = Network(\n",
    "            obs_dim, action_dim, self.atom_size, self.support\n",
    "        ).to(self.device)\n",
    "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
    "        self.dqn_target.eval()\n",
    "        \n",
    "        # optimizer\n",
    "        self.optimizer = optim.Adam(self.dqn.parameters())\n",
    "\n",
    "        # transition to store in memory\n",
    "        self.transition = list()\n",
    "        \n",
    "        # mode: train / test\n",
    "        self.is_test = False\n",
    "\n",
    "    def select_action(self, state: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Select an action from the input state.\"\"\"\n",
    "        # NoisyNet: no epsilon greedy action selection\n",
    "\n",
    "        selected_action = self.dqn(\n",
    "            torch.FloatTensor(state).to(self.device)\n",
    "        )\n",
    "\n",
    "        selected_action = selected_action.detach().cpu().numpy()\n",
    "\n",
    "        print(selected_action)\n",
    "\n",
    "        selected_action = selected_action.argmax()\n",
    "        \n",
    "        if not self.is_test:\n",
    "            self.transition = [state, selected_action]\n",
    "\n",
    "        return selected_action\n",
    "\n",
    "    def step(self, action: np.ndarray) -> Tuple[np.ndarray, np.float64, bool]:\n",
    "        \"\"\"Take an action and return the response of the env.\"\"\"\n",
    "        next_state, reward, terminated, truncated, _ = self.env.step(action)\n",
    "        done = terminated or truncated\n",
    "        \n",
    "        if not self.is_test:\n",
    "            self.transition += [reward, next_state, done]\n",
    "            \n",
    "            # N-step transition\n",
    "            if self.use_n_step:\n",
    "                one_step_transition = self.memory_n.store(*self.transition)\n",
    "            # 1-step transition\n",
    "            else:\n",
    "                one_step_transition = self.transition\n",
    "\n",
    "            # add a single step transition\n",
    "            if one_step_transition:\n",
    "                self.memory.store(*one_step_transition)\n",
    "    \n",
    "        return next_state, reward, done\n",
    "\n",
    "    def update_model(self) -> torch.Tensor:\n",
    "        \"\"\"Update the model by gradient descent.\"\"\"\n",
    "        # PER needs beta to calculate weights\n",
    "        samples = self.memory.sample_batch(self.beta)\n",
    "        weights = torch.FloatTensor(\n",
    "            samples[\"weights\"].reshape(-1, 1)\n",
    "        ).to(self.device)\n",
    "        indices = samples[\"indices\"]\n",
    "        \n",
    "        # 1-step Learning loss\n",
    "        elementwise_loss = self._compute_dqn_loss(samples, self.gamma)\n",
    "        \n",
    "        # PER: importance sampling before average\n",
    "        loss = torch.mean(elementwise_loss * weights)\n",
    "        \n",
    "        # N-step Learning loss\n",
    "        # we are gonna combine 1-step loss and n-step loss so as to\n",
    "        # prevent high-variance. The original rainbow employs n-step loss only.\n",
    "        if self.use_n_step:\n",
    "            gamma = self.gamma ** self.n_step\n",
    "            samples = self.memory_n.sample_batch_from_idxs(indices)\n",
    "            elementwise_loss_n_loss = self._compute_dqn_loss(samples, gamma)\n",
    "            elementwise_loss += elementwise_loss_n_loss\n",
    "            \n",
    "            # PER: importance sampling before average\n",
    "            loss = torch.mean(elementwise_loss * weights)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(self.dqn.parameters(), 10.0)\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        # PER: update priorities\n",
    "        loss_for_prior = elementwise_loss.detach().cpu().numpy()\n",
    "        new_priorities = loss_for_prior + self.prior_eps\n",
    "        self.memory.update_priorities(indices, new_priorities)\n",
    "        \n",
    "        # NoisyNet: reset noise\n",
    "        self.dqn.reset_noise()\n",
    "        self.dqn_target.reset_noise()\n",
    "\n",
    "        return loss.item()\n",
    "        \n",
    "    def train(self, num_frames: int, plotting_interval: int = 200):\n",
    "        \"\"\"Train the agent.\"\"\"\n",
    "        self.is_test = False\n",
    "        \n",
    "        state, _ = self.env.reset(seed=self.seed)\n",
    "        update_cnt = 0\n",
    "        losses = []\n",
    "        scores = []\n",
    "        score = 0\n",
    "\n",
    "        for frame_idx in range(1, num_frames + 1):\n",
    "            action = self.select_action(state)\n",
    "            next_state, reward, done = self.step(action)\n",
    "\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            \n",
    "            # NoisyNet: removed decrease of epsilon\n",
    "            \n",
    "            # PER: increase beta\n",
    "            fraction = min(frame_idx / num_frames, 1.0)\n",
    "            self.beta = self.beta + fraction * (1.0 - self.beta)\n",
    "\n",
    "            # if episode ends\n",
    "            if done:\n",
    "                state, _ = self.env.reset(seed=self.seed)\n",
    "                scores.append(score)\n",
    "                score = 0\n",
    "\n",
    "            # if training is ready\n",
    "            if len(self.memory) >= self.batch_size:\n",
    "                loss = self.update_model()\n",
    "                losses.append(loss)\n",
    "                update_cnt += 1\n",
    "                \n",
    "                # if hard update is needed\n",
    "                if update_cnt % self.target_update == 0:\n",
    "                    self._target_hard_update()\n",
    "\n",
    "            # plotting\n",
    "            if frame_idx % plotting_interval == 0:\n",
    "                self._plot(frame_idx, scores, losses)\n",
    "                \n",
    "        self.env.close()\n",
    "                \n",
    "    def test(self, video_folder: str) -> None:\n",
    "        \"\"\"Test the agent.\"\"\"\n",
    "        self.is_test = True\n",
    "        \n",
    "        # for recording a video\n",
    "        naive_env = self.env\n",
    "        self.env = gym.wrappers.RecordVideo(self.env, video_folder=video_folder)\n",
    "        \n",
    "        state, _ = self.env.reset(seed=self.seed)\n",
    "        done = False\n",
    "        score = 0\n",
    "\n",
    "        iter = 0\n",
    "        \n",
    "        while not done:\n",
    "            iter += 1\n",
    "            if iter % 1000 == 0:\n",
    "                print(f'iter: {iter}, score: {score}')\n",
    "\n",
    "            action = self.select_action(state)\n",
    "            next_state, reward, done = self.step(action)\n",
    "\n",
    "            state = next_state\n",
    "            score += reward\n",
    "        \n",
    "        print(\"score: \", score)\n",
    "        self.env.close()\n",
    "        \n",
    "        # reset\n",
    "        self.env = naive_env\n",
    "\n",
    "    def _compute_dqn_loss(self, samples: Dict[str, np.ndarray], gamma: float) -> torch.Tensor:\n",
    "        \"\"\"Return categorical dqn loss.\"\"\"\n",
    "        device = self.device  # for shortening the following lines\n",
    "        state = torch.FloatTensor(samples[\"obs\"]).to(device)\n",
    "        next_state = torch.FloatTensor(samples[\"next_obs\"]).to(device)\n",
    "        action = torch.LongTensor(samples[\"acts\"]).to(device)\n",
    "        reward = torch.FloatTensor(samples[\"rews\"].reshape(-1, 1)).to(device)\n",
    "        done = torch.FloatTensor(samples[\"done\"].reshape(-1, 1)).to(device)\n",
    "        \n",
    "        # Categorical DQN algorithm\n",
    "        delta_z = float(self.v_max - self.v_min) / (self.atom_size - 1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Double DQN\n",
    "            next_action = self.dqn(next_state).argmax(1)\n",
    "            next_dist = self.dqn_target.dist(next_state)\n",
    "            next_dist = next_dist[range(self.batch_size), next_action]\n",
    "\n",
    "            t_z = reward + (1 - done) * gamma * self.support\n",
    "            t_z = t_z.clamp(min=self.v_min, max=self.v_max)\n",
    "            b = (t_z - self.v_min) / delta_z\n",
    "            l = b.floor().long()\n",
    "            u = b.ceil().long()\n",
    "\n",
    "            offset = (\n",
    "                torch.linspace(\n",
    "                    0, (self.batch_size - 1) * self.atom_size, self.batch_size\n",
    "                ).long()\n",
    "                .unsqueeze(1)\n",
    "                .expand(self.batch_size, self.atom_size)\n",
    "                .to(self.device)\n",
    "            )\n",
    "\n",
    "            proj_dist = torch.zeros(next_dist.size(), device=self.device)\n",
    "            proj_dist.view(-1).index_add_(\n",
    "                0, (l + offset).view(-1), (next_dist * (u.float() - b)).view(-1)\n",
    "            )\n",
    "            proj_dist.view(-1).index_add_(\n",
    "                0, (u + offset).view(-1), (next_dist * (b - l.float())).view(-1)\n",
    "            )\n",
    "\n",
    "        dist = self.dqn.dist(state)\n",
    "        log_p = torch.log(dist[range(self.batch_size), action])\n",
    "        elementwise_loss = -(proj_dist * log_p).sum(1)\n",
    "\n",
    "        return elementwise_loss\n",
    "\n",
    "    def _target_hard_update(self):\n",
    "        \"\"\"Hard update: target <- local.\"\"\"\n",
    "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
    "                \n",
    "    def _plot(\n",
    "        self, \n",
    "        frame_idx: int, \n",
    "        scores: List[float], \n",
    "        losses: List[float],\n",
    "    ):\n",
    "        \"\"\"Plot the training progresses.\"\"\"\n",
    "        clear_output(True)\n",
    "        plt.figure(figsize=(20, 5))\n",
    "        plt.subplot(131)\n",
    "        plt.title('frame %s. score: %s' % (frame_idx, np.mean(scores[-10:])))\n",
    "        plt.plot(scores)\n",
    "        plt.subplot(132)\n",
    "        plt.title('loss')\n",
    "        plt.plot(losses)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n",
    "\n",
    "You can see the [code](https://github.com/Farama-Foundation/Gymnasium/blob/main/gymnasium/envs/classic_control/cartpole.py) and [configurations](https://github.com/Farama-Foundation/Gymnasium/blob/main/gymnasium/envs/classic_control/cartpole.py#L91) of CartPole-v1 from Farama Gymnasium's repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment\n",
    "\n",
    "# env: gym.Env[Tuple[float, float, float, float], Literal[0, 1]] = gym.make(\"CartPole-v1\", max_episode_steps=200, render_mode=\"rgb_array\")\n",
    "\n",
    "from x2 import X2Env\n",
    "\n",
    "env = X2Env()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 777\n",
    "\n",
    "def seed_torch(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.backends.cudnn.enabled:\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "seed_torch(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 4\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "num_frames = 10000\n",
    "memory_size = 10000\n",
    "batch_size = 128\n",
    "target_update = 100\n",
    "\n",
    "# train\n",
    "agent = DQNAgent(env, memory_size, batch_size, target_update, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent.train(num_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "Run the trained agent (1 episode)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guillaume/rainbow-is-all-you-need/.venv/lib/python3.8/site-packages/gymnasium/wrappers/record_video.py:87: UserWarning: \u001b[33mWARN: Overwriting existing videos at /home/guillaume/rainbow-is-all-you-need/videos/rainbow folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n",
      "/home/guillaume/rainbow-is-all-you-need/.venv/lib/python3.8/site-packages/gymnasium/wrappers/monitoring/video_recorder.py:62: UserWarning: \u001b[33mWARN: Disabling video recorder because environment <X2Env instance> was not initialized with any compatible video mode between `rgb_array` and `rgb_array_list`\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 1000, score: 6\n",
      "iter: 2000, score: 6\n",
      "iter: 3000, score: 6\n",
      "iter: 4000, score: 6\n",
      "iter: 5000, score: 6\n",
      "iter: 6000, score: 6\n",
      "iter: 7000, score: 6\n",
      "iter: 8000, score: 6\n",
      "iter: 9000, score: 6\n",
      "iter: 10000, score: 6\n",
      "iter: 11000, score: 6\n",
      "iter: 12000, score: 6\n",
      "iter: 13000, score: 6\n",
      "iter: 14000, score: 6\n",
      "iter: 15000, score: 6\n",
      "iter: 16000, score: 6\n",
      "iter: 17000, score: 6\n",
      "iter: 18000, score: 6\n",
      "iter: 19000, score: 6\n",
      "iter: 20000, score: 6\n",
      "iter: 21000, score: 6\n",
      "iter: 22000, score: 6\n",
      "iter: 23000, score: 6\n",
      "iter: 24000, score: 6\n",
      "iter: 25000, score: 6\n",
      "iter: 26000, score: 6\n",
      "iter: 27000, score: 6\n",
      "iter: 28000, score: 6\n",
      "iter: 29000, score: 6\n",
      "iter: 30000, score: 6\n",
      "iter: 31000, score: 6\n",
      "iter: 32000, score: 6\n",
      "iter: 33000, score: 6\n",
      "iter: 34000, score: 6\n",
      "iter: 35000, score: 6\n",
      "iter: 36000, score: 6\n",
      "iter: 37000, score: 6\n",
      "iter: 38000, score: 6\n",
      "iter: 39000, score: 6\n",
      "iter: 40000, score: 6\n",
      "iter: 41000, score: 6\n",
      "iter: 42000, score: 6\n",
      "iter: 43000, score: 6\n",
      "iter: 44000, score: 6\n",
      "iter: 45000, score: 6\n",
      "iter: 46000, score: 6\n",
      "iter: 47000, score: 6\n",
      "iter: 48000, score: 6\n",
      "iter: 49000, score: 6\n",
      "iter: 50000, score: 6\n",
      "iter: 51000, score: 6\n",
      "iter: 52000, score: 6\n",
      "iter: 53000, score: 6\n",
      "iter: 54000, score: 6\n",
      "iter: 55000, score: 6\n",
      "iter: 56000, score: 6\n",
      "iter: 57000, score: 6\n",
      "iter: 58000, score: 6\n",
      "iter: 59000, score: 6\n",
      "iter: 60000, score: 6\n",
      "iter: 61000, score: 6\n",
      "iter: 62000, score: 6\n",
      "iter: 63000, score: 6\n",
      "iter: 64000, score: 6\n",
      "iter: 65000, score: 6\n",
      "iter: 66000, score: 6\n",
      "iter: 67000, score: 6\n",
      "iter: 68000, score: 6\n",
      "iter: 69000, score: 6\n",
      "iter: 70000, score: 6\n",
      "iter: 71000, score: 6\n",
      "iter: 72000, score: 6\n",
      "iter: 73000, score: 6\n",
      "iter: 74000, score: 6\n",
      "iter: 75000, score: 6\n",
      "iter: 76000, score: 6\n",
      "iter: 77000, score: 6\n",
      "iter: 78000, score: 6\n",
      "iter: 79000, score: 6\n",
      "iter: 80000, score: 6\n",
      "iter: 81000, score: 6\n",
      "iter: 82000, score: 6\n",
      "iter: 83000, score: 6\n",
      "iter: 84000, score: 6\n",
      "iter: 85000, score: 6\n",
      "iter: 86000, score: 6\n",
      "iter: 87000, score: 6\n",
      "iter: 88000, score: 6\n",
      "iter: 89000, score: 6\n",
      "iter: 90000, score: 6\n",
      "iter: 91000, score: 6\n",
      "iter: 92000, score: 6\n",
      "iter: 93000, score: 6\n",
      "iter: 94000, score: 6\n",
      "iter: 95000, score: 6\n",
      "iter: 96000, score: 6\n",
      "iter: 97000, score: 6\n",
      "iter: 98000, score: 6\n",
      "iter: 99000, score: 6\n",
      "iter: 100000, score: 6\n",
      "iter: 101000, score: 6\n",
      "iter: 102000, score: 6\n",
      "iter: 103000, score: 6\n",
      "iter: 104000, score: 6\n",
      "iter: 105000, score: 6\n",
      "iter: 106000, score: 6\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb Cell 25\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m video_folder\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvideos/rainbow\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m agent\u001b[39m.\u001b[39;49mtest(video_folder\u001b[39m=\u001b[39;49mvideo_folder)\n",
      "\u001b[1;32m/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb Cell 25\u001b[0m line \u001b[0;36m2\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=260'>261</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39miter\u001b[39m \u001b[39m%\u001b[39m \u001b[39m1000\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=261'>262</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39miter: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39miter\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, score: \u001b[39m\u001b[39m{\u001b[39;00mscore\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=263'>264</a>\u001b[0m action \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mselect_action(state)\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=264'>265</a>\u001b[0m next_state, reward, done \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep(action)\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=266'>267</a>\u001b[0m state \u001b[39m=\u001b[39m next_state\n",
      "\u001b[1;32m/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb Cell 25\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=121'>122</a>\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Select an action from the input state.\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=122'>123</a>\u001b[0m \u001b[39m# NoisyNet: no epsilon greedy action selection\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=124'>125</a>\u001b[0m selected_action \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdqn(\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=125'>126</a>\u001b[0m     torch\u001b[39m.\u001b[39;49mFloatTensor(state)\u001b[39m.\u001b[39;49mto(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice)\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=126'>127</a>\u001b[0m )\u001b[39m.\u001b[39margmax()\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=128'>129</a>\u001b[0m selected_action \u001b[39m=\u001b[39m selected_action\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=130'>131</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_test:\n",
      "File \u001b[0;32m~/rainbow-is-all-you-need/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb Cell 25\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Forward method implementation.\"\"\"\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m     dist \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdist(x)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m     q \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msum(dist \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupport, dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m q\n",
      "\u001b[1;32m/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb Cell 25\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m val_hid \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalue_hidden_layer(feature))\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m advantage \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madvantage_layer(adv_hid)\u001b[39m.\u001b[39mview(\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m     \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout_dim, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39matom_size\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=45'>46</a>\u001b[0m value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalue_layer(val_hid)\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39matom_size)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=46'>47</a>\u001b[0m q_atoms \u001b[39m=\u001b[39m value \u001b[39m+\u001b[39m advantage \u001b[39m-\u001b[39m advantage\u001b[39m.\u001b[39mmean(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, keepdim\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=48'>49</a>\u001b[0m dist \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39msoftmax(q_atoms, dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/rainbow-is-all-you-need/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb Cell 25\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=65'>66</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=66'>67</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Forward method implementation.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=67'>68</a>\u001b[0m \u001b[39m    \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=68'>69</a>\u001b[0m \u001b[39m    We don't use separate statements on train / eval mode.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=69'>70</a>\u001b[0m \u001b[39m    It doesn't show remarkable difference of performance.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=70'>71</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=71'>72</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=72'>73</a>\u001b[0m         x,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=73'>74</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight_mu \u001b[39m+\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight_sigma \u001b[39m*\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight_epsilon,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=74'>75</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_mu \u001b[39m+\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_sigma \u001b[39m*\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_epsilon,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guillaume/rainbow-is-all-you-need/08.rainbow.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=75'>76</a>\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "video_folder=\"videos/rainbow\"\n",
    "agent.test(video_folder=video_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.is_test = True\n",
    "\n",
    "# naive_env = self.env\n",
    "        # self.env = gym.wrappers.RecordVideo(self.env, video_folder=video_folder)\n",
    "        \n",
    "state, _ = agent.env.reset(seed=agent.seed)\n",
    "done = False\n",
    "score = 0\n",
    "\n",
    "# iter = 0\n",
    "\n",
    "# while not done and iter < 1000:\n",
    "#     iter += 1\n",
    "#     if iter % 1000 == 0:\n",
    "#         print(f'iter: {iter}, score: {score}')\n",
    "\n",
    "#     action = agent.select_action(state)\n",
    "#     next_state, reward, done = agent.step(action)\n",
    "\n",
    "#     state = next_state\n",
    "#     score += reward\n",
    "\n",
    "# print(\"score: \", score)\n",
    "# agent.env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[98.46086  99.50452  97.584465 95.32867 ]]\n",
      "1\n",
      "[[0 2 0 0 0]\n",
      " [0 5 0 0 0]\n",
      " [0 3 0 0 0]\n",
      " [0 5 0 0 0]\n",
      " [0 3 0 0 0]]\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "action = agent.select_action(state)\n",
    "next_state, reward, done = agent.step(action)\n",
    "print(action)\n",
    "print(next_state[1:].reshape(5, 5))\n",
    "\n",
    "state = next_state\n",
    "score += reward\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <video width=\"320\" height=\"240\" alt=\"test\" controls>\n",
       "        <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\"/>\n",
       "        </video>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Played: videos/rainbow/rl-video-episode-0.mp4\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import glob\n",
    "import io\n",
    "import os\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "\n",
    "def ipython_show_video(path: str) -> None:\n",
    "    \"\"\"Show a video at `path` within IPython Notebook.\"\"\"\n",
    "    if not os.path.isfile(path):\n",
    "        raise NameError(\"Cannot access: {}\".format(path))\n",
    "\n",
    "    video = io.open(path, \"r+b\").read()\n",
    "    encoded = base64.b64encode(video)\n",
    "\n",
    "    display(HTML(\n",
    "        data=\"\"\"\n",
    "        <video width=\"320\" height=\"240\" alt=\"test\" controls>\n",
    "        <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\"/>\n",
    "        </video>\n",
    "        \"\"\".format(encoded.decode(\"ascii\"))\n",
    "    ))\n",
    "\n",
    "\n",
    "def show_latest_video(video_folder: str) -> str:\n",
    "    \"\"\"Show the most recently recorded video from video folder.\"\"\"\n",
    "    list_of_files = glob.glob(os.path.join(video_folder, \"*.mp4\"))\n",
    "    latest_file = max(list_of_files, key=os.path.getctime)\n",
    "    ipython_show_video(latest_file)\n",
    "    return latest_file\n",
    "\n",
    "\n",
    "latest_file = show_latest_video(video_folder=video_folder)\n",
    "print(\"Played:\", latest_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
